\documentclass[10pt,a4paper,oneside]{article}
%\renewcommand\abstractname{Executive Summary}
%\renewcommand*\thesection{\arabic{section}}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\usepackage{algorithm2e}
\usepackage{tocloft}
\usepackage{graphicx}
\usepackage[section]{placeins}
\usepackage{array}
\usepackage{rotating}
\usepackage{float}
\usepackage{pdflscape}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage{txfonts}
\usepackage{url}
\usepackage{graphics}
\usepackage[titletoc,toc,title]{appendix}
\usepackage{varioref}
\usepackage{verbatim}
\usepackage[usenames,dvipsnames,table]{xcolor}
\usepackage{listings}
\usepackage{color}
\usepackage{acronym}
\usepackage{url}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{fancyhdr}
%\usepackage[table]{xcolor}
\usepackage{hhline}
\usepackage{pdfpages}
\usepackage{tikz}
%\usepackage{siunitx}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\usetikzlibrary{backgrounds, arrows,positioning, shapes,patterns, chains,calc}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{ %
  language=R,                     % the language of the code
  basicstyle=\footnotesize,       % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it's 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  title=\lstname,                 % show the filename of files included with \lstinputlisting;
                                  % also try caption instead of title
  keywordstyle=\color{blue},      % keyword style
  commentstyle=\color{dkgreen},   % comment style
  stringstyle=\color{mauve},      % string literal style
  morekeywords={*,...}            % if you want to add more keywords to the set
}
\renewcommand{\lstlistingname}{Code Extract} 
%\renewcommand{\listlstlistingname}{List of Code Extracts}
\newcommand{\degree}{\ensuremath{^\circ}}
\renewcommand{\headrulewidth}{0pt} % remove the header rule
\newcommand{\includecode}[2][c]{\lstinputlisting[caption=#2, escapechar=, style=custom#1]{#2}}
\renewcommand*{\listlistingname}{List of XYZ}
 
\addtolength{\voffset}{-1.5cm}
\addtolength{\hoffset}{-1.3cm}
\addtolength{\textwidth}{3cm}
\addtolength{\textheight}{120pt}
\addtolength{\marginparwidth}{-100pt}
\addtolength{\oddsidemargin}{-0.3in}
\addtolength{\evensidemargin}{-0.3in}
\textwidth 6.6in
 
\setlength\cftparskip{1pt}
\setlength{\parindent}{0pt}
% leftmark shows the chapter, rightmark shows the section.
\fancyhead{}
\fancyfoot[L]{}% empty left
\fancyfoot[R]{ % right
}
\pagestyle{fancy}
% Tikz Style Blocks

\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
    text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse,fill=red!20, node distance=3cm,
    minimum height=2em]


\bibliographystyle{ieeetr}
\title {EE40150 - Final Year Project- Investigation into the Precision Time Protocol}
\author {James Cox
\\ Department of Electrical and Electronic Engineering \\
\\
University of Bath}
\date{\today}
\begin{document}

\maketitle
\vfill

\begin{abstract}
There is an ever increasing importance to synchronise clocks or processes in several industries including telecommunications and power distribution.
With the current method of synchronisation using the \acf{GPS} high precision clocks onboard the satellites, this method has some limitations to it due to its jammiblilty. 
Therefore solely relying on this technology would not be wise, and an alternative method should be used alongside \ac{GPS}. 
Examples of such methods are a distributed network for synchronisation: either the \ac{NTP} or the \acf{PTP}. 
This project investigates the newer of the two technologies (\ac{PTP}) and how it performs on an Ethernet network.
Some existing hardware and software clocks were used to try and quantify network delay and how it changes at different points along the network.
Finally packet metrics were used to attempt to quantify this delay. 

%Some info on results.
\end{abstract}
\newpage
\tableofcontents
\newpage
\section*{Acronyms}
\begin{acronym}
\acro{BMC}{Best Master Clock}
\acro{CSAC}{Chip Scale Atomic Clock}
\acro{CSMA/CD}{Carrier Sense Multiple Access with Collision Detection}
\acro{CSV}{Comma Seperated Variable}
\acro{E2E}{End-to-End}
\acro{GM}{Grandmaster}
\acro{GNU}{GNU's Not Unix}
\acro{GPS}{Global Positioning System}
\acro{IDE}{Integrated Development Environment}
\acro{IEEE}{Institute of Electrical and Electronic Engineers}
\acro{ITU}{International Telecommunication Union}
\acro{LAN}{Local Area Network}
\acro{MAC}{Media Access Control}
\acro{MAFE}{Maximum Average Frequency Error}
\acro{MATIE}{Maximum Average Time Interval Error}
\acro{NERC}{North American Electric Reliability Company}
\acro{NTP}{Network Time Protocol}
\acro{P2P}{Peer-to-Peer}
\acro{PPS}{Pulse per Second}
\acro{PTP}{Precision Time Protocol}
\acro{PTPd}{PTP Daemon}
\acro{SA}{Security Association}
\acro{SNTP}{Simple Network Time Protocol}
\acro{SRS}{Stanford Research Systems}
\acro{TAI}{International Atomic Time}
\acro{TDEV}{Time Deviation}
\acro{UTC}{Coordinated Universal Time}
\end{acronym}
\newpage
\listoffigures
\newpage
\listoftables
\newpage
\lstlistoflistings
\newpage
\section{Introduction}
In a few high profile applications there is an ever increasing requirement for high accurate clocks.  
These clocks may be used for generating an accurate timestamp, such as in the telecommunications industry,  or a way to synchronise processes in the case of the automotive industry. 
Multiple clocks will be used in these applications, and thus they all should be synchronised with one another. \\

It may not be feasible to have a high accuracy atomic clock (or \ac{CSAC}) due to space or cost constraints.
An alternative to this would be to use a \ac{GPS} receiver and time can then be synchronised to the accurate atomic clocks onboard the \ac{GPS} satellites.
Using high accuracy clocks like the ones mentioned would help to reduce any clock accuracies.\\

There are two types of clock inaccuracies when synchronising clocks. 
Firstly they may have started at a different time relative to the others. 
Adjusting for this error is called offset correction. 
The second effect is due to the fact that the clocks do not necessarily run at exactly the same speed.
Therefore they need to be continuously adjusted (also known as drift correction.
The amount of drift correction required depends on the quality of the clock.
Appendix \ref{clockaccuracies} shows a table of clocks and their corresponding accuracies.\\

The following industries are examples that would require this level of timing accuracy.

\begin{description}
\item[Automation Industry] \hfill \\ Processes will need to be synchronised exactly, and can only be if their clocks are in sync with one another.
If clocks are in sync then processes can also be separated away from communication between each machine and the processing of the control commands. \cite{IEEEApplications} 
\item[Power Transmission] \hfill \\ Time synchronisation is very important in the power transmission industry. An example of a situation where timing would have mitigated a fault from occurring is the North American blackout in August 2003 \cite{PTPFuturePower}. 
It made it difficult for the investigation team to be able to sort through the data received when the timestamps were gathered from an inaccurate clock. 
From the events of this blackout a regulation was put in place to define a minimum absolute accuracy for timestamped data.
The adoption of the \ac{NERC}  Standard PRC018-1 in 2006 \cite{NERCPRC0181} made it a requirement for any substation in the USA to log data to a minimum accuracy. The timestamped data must be accurate to within 2ms relative  to \ac{UTC}.
\item[Telecommunications] \hfill\\ In telecommunications, timing protocols are considered when networks need to be synchronised or if mobile base stations need synchronisation pulses.
With the increase in \ac{GPS} jamming, systems such as 4G mobile telephony must rely on other timing methods in case \ac{GPS} is affected. 
\end{description}

All of the industries mentioned above could feasibly use \ac{GPS} for a highly accurate timing reference.
But if there is an issue with the system, for example a jamming incident, then there will be some major consequences should timing drift.
It is known that jamming of GPS receivers is becoming more common and thus an alternative method of time synchronisation should be used.  \cite{GPSJamming}
There are multiple cases where jamming may occur (both accidental and intentional) and thus a way of synchronising time with this threat must be realised. \\

One way of realising this is by using a distributed timing system, such as \ac{NTP} or \ac{PTP}. 
This would allow for nodes to be able to synchronise their clocks with a more accurate time source.

\subsection{How the \acf{NTP} Works}
\textit{This section has been taken from the Interim Report \cite{interimReport}and has been modified. Some sections however may be exact copies. }
This is a technology originally designed in 1985 and is used to synchronise clocks over a packet switched network. 
It is able to achieve synchronisation with \ac{UTC} within a few milliseconds, but can maintain sub-millisecond accuracy on a \ac{LAN} if ideal conditions are met. 
Errors due to different packet routes or network congestion can reduce this ~accuracy by 100ms or more \cite{NTPWhitePaper}.\\

\ac{NTP} uses a client-server hierarchy split into stratums. 
Figure \ref{fig:NTPHierarchy} on the next page shows the typical stratums numbered from 0 to 3. 

\begin{figure}[H]
\centering
\includegraphics[scale = 0.3]{Figures/NTPDiagram.eps}
\caption{\ac{NTP} Network Hierarchy \cite{figRef:NTPHierarchy}}
\label{fig:NTPHierarchy}
\end{figure}

The reference clocks located in stratum 0 are high precision such as  atomic clocks or they utilise \ac{GPS} synchronisation.  
The clocks in stratum 2 will base their time off of the clocks in stratum 1. 
A number of the clocks in stratum 1 will be used for time synchronising each clock in stratum 2. This is done so that the time is more accurate and robust. 
Within a stratum, clocks may also synchronise for sanity checking to ensure that all clocks within a Stratum are accurate between each other.
Any layers below Stratum 2 will mirror the same algorithm, and there can be up to 15 layers. 
Stratum 16 is reserved for clocks that are not synchronised with \ac{NTP} \cite{NTP}.\\

\ac{SNTP} is used in applications which do not require a high timing accuracy and achieves this by ignoring drift values.
Therefore it is recommended that \ac{SNTP} is only used in the higher stratums \cite{SNTP}.
The \ac{SNTP} specification is part of the \ac{NTP} specification \cite{NTPV4Specification}. \\

Issues arise when synchronising time over a packet switched network where sub millisecond accuracies are required.  
\ac{PTP} was developed as a successor to the existing \ac{NTP} standard which aims to reach higher levels of accuracy. 
Meeting this value of accuracy is very difficult however with a traditional Ethernet network. \\

When standard switches are used, the packet delay between two nodes is indeterminate. 
This may be because the packet route from A to B changes depending on network load, or a packet may be held in a switch for an unspecified amount of time whilst working with other data.
Therefore this is undesired for \ac{PTP} as this packet delay must be taken into account when working out the clock offset. 
Specific timing switches can be used which will prioritise \ac{PTP} packets, but these may not be available in existing networks or be too expensive to be suitable. 

\subsection{How the \acf{PTP} Works}

There are a few important elements of how \ac{PTP} works in order to be able to start the project. 
These are: general \ac{PTP} operation and the \ac{BMC} algorithm.
A comparison between \ac{NTP} and \ac{PTP} will be made, as well as any security aspects regarding \ac{PTP}.

\subsubsection{PTP Explanation}

\ac{PTP} uses a similar master-slave hierarchy of \ac{NTP}, but it does not  use the stratum method. 
Instead it uses domains which separate out \ac{PTP} synchronisation networks. 
The master clock for the domain will broadcast out the current time to all of the other clocks on the network using a multicast message.
In IEEE1588-2008 \cite{IEEE1588}this can occur up to one message every 32 $\frac{1}{4}$ ms. \\

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{Figures/DelayPTP.eps}
\label{fig:ptptiming}
\caption{PTP timing diagram (based on diagram referenced here \cite{PTPTiming})}
\end{figure}

The list below shows the basic steps that \ac{PTP} follows \cite{IEEE1588}:

\begin{enumerate}
\item Broadcast begins at $t_{1}$ where the master sends a \textit{sync} message to all clocks on the domain.
\item Each slave clock takes a note of when the message was received using their local clock.  
This timestamp is labelled $t_{1}^{'}$.
\item An optional \textit{follow\_up} message may be sent which includes an accurate timestamp of $t_{1}$. 
This step occurs if the master clock does not have the capability to create an accurate timestamp when sending the \textit{sync} message.
\item In order for the slave to synchronise with the master, the round trip delay needs to be known. 
Therefore a \textit{delay\_req} message is sent by the slave clock at time $t_{2}$. 
\item The master will respond to this message with a \textit{delay\_resp} message. this timestamp is called $t_{2}^{'}$.
\end{enumerate}

At this point $t_{1}$, $t_{1}^{'}$, $t_{2}$ and $t_{2}^{'}$ are now known. \\

If we define $d$ as the transit time, and $\widetilde{o}$ as the constant offset between the two clocks, the one one delay is: 

\begin{equation}
\label{eqn:t1delay}
t_{1}^{'} - t_{2} = \widetilde{o} + d
\end{equation}

\begin{equation}
\label{eqn:t2delay}
t_{2}^{'} - t_{2} = - \widetilde{o} + d
\end{equation}

If we rearrange equation \ref{eqn:t2delay} for $d$ : 

\begin{equation}
\label{eqn:3}
d = t_{2}^{'} - t_{2} + \widetilde{o}
\end{equation}

Substituting Equation \ref{eqn:3} into \ref{eqn:t1delay}: 
\begin{equation}
t_{1}^{'} - t_{1} = \widetilde{o} + t_{2}^{'} - t_{2} + \widetilde{o}
\end{equation}
\begin{equation}
t_{1}^{'} - t_{1} -  t_{2}^{'} +  t_{2} = 2 \widetilde{o}
\end{equation}
\begin{equation}
\widetilde{o} = \frac{t_{1}^{'} - t_{1} -  t_{2}^{'} +  t_{2}}{2}
\end{equation}
\\

The offset is now known and can be adjusted for. 
The following assumptions have been made to create the calculations above. 
\begin{enumerate}
\item Message exchange occurs over such a short period of time that the delay is assumed to be constant. 
\item Transit time is symmetrical (i.e. time from master to slave is the same as slave to master). 
\item Both the slave and the master can measure the transmit and receive times of messages accurately (~ignoring clock drift).
\end{enumerate}

\subsubsection{Comparison with \ac{NTP}}

The \acf{PTP} was first developed in 2003 with the intention to build on the existing \ac{NTP} standard. 
A new \ac{PTP} standard was introduced in 2008 with some new features such as boundary clocks and using domains instead of stratums. 
\ac{NTP} is used by Microsoft to synchronise clocks over the internet, whereas \ac{PTP} is used in industry where higher accuracy is needed.
These changes and comparison with \ac{NTP} have been tabulated below, Table \ref{table:ntpptp}.

\begin{table}[h]
\centering
\caption{\ac{NTP} vs \ac{PTP} Version 1 vs \ac{PTP} Version 2}
\begin{tabular}{| p{4cm} || c |c | c| } \hline
\cellcolor{Black}\textcolor{white}{\textbf{ Feature }}  &  \cellcolor{Black}\textcolor{White}{\textbf{NTP}} & \cellcolor{Black}\textcolor{White}{\textbf{ IEEE1588-2002}} & \cellcolor{Black}\textcolor{White}{\textbf{IEEE1588-2008}} \\ \hline
Time System & \ac{UTC} & \ac{TAI} & \ac{TAI} - can choose epoch \\ \hline
Transparent Clocks  & No & No  & Yes\\ \hline
Unicast  & no &  No  &  Yes \\ \hline
Domains  & Subdomain Name Fields & Subdomain Name Fields &  Domain Numbers\\ \hline
Clock Quality & None & Data Field Stratum & Clock Accuracy / Clock Class \\ \hline
Selection Algorithm For Best Clock & Unknown & Election Based & Hierarchical \\ \hline
\multirow{5}{*}{Unique Features} & & & Alternate Time Scale \\ 
 & & & Grandmaster Cluster \\ 
 & None & Noise Reduction&  Unicast Masters \\ 
 & & & Alternate Master \\ 
 & & & Path Trace \\  \hline  
\end{tabular}
\label{table:ntpptp}
\end{table}

\subsubsection{A Typical \ac{PTP} Network}
\label{ref:PTPNetwork}
There are several different configurations for a \ac{PTP} network to take using the following pieces of hardware.

\begin{description}
\item[Grandmaster Clock] The grandmaster clock is the main source of time synchronisation using \ac{PTP} within the same \ac{PTP} domain. 
This clock will consist of a highly accurate timing source, such as a \ac{CSAC} or be based off of a \ac{GPS} time reference. 
This clock is picked using the \ac{BMC} algorithm.
\item[Ordinary Clock] An ordinary clock is a \ac{PTP} clock with a single ethernet port. 
They are also called nodes in a \ac{PTP} network.
These are the most common types of clocks on the \ac{PTP} network as these are the end nodes that are then connected to devices that require synchronisation.
\item[Boundary Clock] A boundary clock is a replacement to a standalone switch.
It usually has multiple \ac{PTP} ports and thus provides a link between domains. 
Boundary clocks prioritise \ac{PTP} packets in order for the one way delay to be reduced as much as possible. 
\item[Transparent Clock]  A transparent clock main role is to account for switch delay by updating the time interval field of the \ac{PTP} packet.
There are two types of transparent clocks which might be used in a typical network which are \ac{E2E} and \ac{P2P} transparent clocks.\\

They both measure the event message transit time (also known as the resident time) for both $sync$ and $Delay\_rq$ messages. 
This information is then added to the correction field in the two messages.
The slave clock can then use this information to work out a more accurate offset.
Note however that \ac{E2E} clocks in particular do not account for the propagation delay of the link. \\

A \ac{P2P} clock also takes into account the upstream delay, which is the propagation delay between the two transparent clocks.
This time is then added on to the offset mentioned previously. 
\end{description}

\begin{figure}
\centering
\includegraphics[scale=0.6]{Figures/PTPNetwork.eps}
\caption{A Typical PTP Network \cite{CiscoPTP}}
\label{PTPNet}
\end{figure}

There are several different network configurations that could be used when using a \ac{PTP} network.
The most minimal network configuration would include a grandmaster clock and a single slave, but they can get more complicated if boundary and transparent clocks are used.
%The diagram below outlines some possible topologies for \ac{PTP} networks. 
\begin{comment}
\begin{figure}
\centering
	\begin{subfigure}{\textwidth}
	\centering
		\begin{subfigure}{0.5\textwidth}
		\centering
		%\includegraphics[scale=0.5]{Figures/NetworkDiagrams/1GMMultipleSlave.eps}
		\caption{One Grandmaster Multiple Slaves}
		\end{subfigure}%
		\begin{subfigure}{0.5\textwidth}
		\centering
		%\includegraphics[scale=0.5]{Figures/NetworkDiagrams/1GMMultipleSlavewithBoundary.eps}
		\caption{One Grandmaster Multiple Slaves with Boundary Clock}
		\end{subfigure}
	\end{subfigure}%
	\begin{subfigure}{\textwidth}
	\centering
		\begin{subfigure}{0.5\textwidth}
		\centering
		%\includegraphics[scale=0.5]{Figures/NetworkDiagrams/MultipleGMMultipleSlave.eps}
		\caption{Multiple Grandmaster Multiple Slaves}
		\end{subfigure}%
		\begin{subfigure}{0.5\textwidth}
		\centering
		%\includegraphics[scale=0.5]{Figures/NetworkDiagrams/MultipleDomains.eps}
		\caption{Multiple Domains}
		\end{subfigure}
	\end{subfigure}
\label{fig:NetworkDiagrams}
\caption{Examples of some \ac{PTP} Networks}
\end{figure}
\end{comment}


There are some areas of concern with \ac{PTP} that will be addressed in this report. 
Firstly it is unknown how well \ac{PTP} operates on a busy network when standard switches are used instead of boundary clocks.
Secondly there are some security concerns with \ac{PTP} as all messages are transmitted in plain text. 
\subsubsection{\acf{BMC}}
\label{ref:BMC}

The \ac{BMC} is used to determine the most suitable clock to be the master (or the grandmaster) of a \ac{PTP} network. 
The following criteria are used when determine which clock on the network is the best.

\begin{description}
\item[Identifer] This is a unique identifier which is constructed from the device's \ac{MAC} address.
\item[Quality] This refers to the technology used to implement the clock, and takes into account the expected time deviation.
\item[Priority] This is an admin assigned precedence to select a particular grandmaster. 
In IEEE1588-2008 there are 2 8bit priority fields.
\item[Variance] This refers to the stability of the clock based on its performance against the \ac{PTP} reference. 
\end{description}

The 2008 standard uses a hierarchical selection algorithm system, which is outlined below.

\begin{enumerate}
\item Priority 1
\item Class
\item Accuracy
\item Variance
\item Priority 2
\item Unique Identifier (tie break)
\end{enumerate}

The \ac{BMC} algorithm is used to determine each master, and ultimately the grandmaster of the entire \ac{PTP} network. 
\begin{comment}
\subsubsection{Management Commands}
\label{ref:ManagementCommands}

- explanation of the management portion of PTP
	+ explain the distributed maangement structure etc
\end{comment}

\subsection{Project Description}
This project aims to investigate \ac{PTP} performance on a heavily used Ethernet network, and to attempt to quantify \ac{PTP} performance using packet metrics. \\
There are also some deliverables as part of the Final Year Project which are: an interim report, a log book, a final year report and a poster. 
These deliverables, along with the sub tasks involved in order to complete them have been detailed in the Gantt chart, as seen in Appendix \ref{app:ganttchart}.
The following project objectives have been identified:


\begin{description}
\item[Learn about \ac{PTP} and other work in relation to the protocol] \hfill \\ 
This stage would occur at the beginning of the project to understand how \ac{PTP} works.
This is important so work can then be carried out to investigate \ac{PTP} performance on a network. 
This section will also include any relevant literature reviews
\item[Collect PTP Data] \hfill \\ 
In parallel with the above, PTP data can be collected. 
This will be monitoring the performance of \ac{PTP} across the network as well as how using multiple types of grandmaster/slaves affect the performance. 
Different clock locations in the network will also be considered.
\item[Implement packet metric scripts] \hfill \\ 
To be able to understand the performance of the network, some packet metric scripts will be created. 
A suitable language will be chosen once this part of the project begins.
\item[Determine packet performance using these scripts] \hfill \\
In combination with the collected data and the metric script development, the scripts will be run with the data collected and \ac{PTP} performance will be evaluated based on them. 

Multiple window sizes and types of metric will be used to quantify network performance.
\item[Test Chronos' equipment and provide feedback] \hfill \\ 
As Chronos has provided this project with some equipment, this equipment will also be thoroughly tested and any information gathered can be passed to them once the project is completed.
\item[Documentation] \hfill \\ It was noted that it would be beneficial to document as much as possible about the hardware used, which can then be fed back to Chronos if need be. 
This would also be useful internally. 
\item[Investigate into security measures] \hfill \\ Some research into how to secure \ac{PTP} will be made along with some recommendations where applicable. 
As \ac{PTP} messages are sent in plain text there is room for exploitation or hacking of the protocol.
\end{description}


\section{Literature Review}

With the following objectives and tasks in mind, a literature review was performed on any relavent material. 

\subsection{Definitions and Terminology for Synchronisation in Packet Networks \cite{ITUPacketMetrics}}
\label{metricReview}

The first paper defines a number of definitions and terms when dealing with packet synchronisation. The areas of interest in this report were packet metrics which are found in Appendix I3 and I4.  
These can be split into three sections: Packet Selection Methods, Packet Metrics without Pre-filtering, and Packet Metrics with Pre-filtering.

\subsubsection{Packet Selection Methods}

There are two main methods of selecting packets when calculating a packet metric: either using a selection technique at the same time as the packet metric calculation, or as a pre-processing technique before the metric calculation is performed.  \\

Packet selection, when integrated with the calculation, is very useful when the behaviour of a network is to be determined with respect to its packet delay variation. 
This is because it provides a generic method that is independent to a particular slave clock implementation \cite {ITUPacketMetrics}.
This packet selection method is also known as a Class B metric. \\

The other method uses a pre-processing technique which preselects packets from a time window. 
By doing this the process will average out any inconsistencies in the delays, thus resembling a clock running in steady state. 
Therefore this method is more suitable when trying to specify network limits. This is known as a class A metric). \\


There are four examples of packet selection methods that are mentioned in the recommendation report. 
These are: Minimum Packet Selection Method, Percentile Packet Selection Method, Band Packet Selection Method and Cluster Range Packet Selection Method. 
The normal packet selection method uses a mean value across the window, whereas the minimum packet selection method takes the lowest value.
The band packet and percentile packet uses a band mean type method, with the percentile version setting the lower band to 0. 
These will be discussed in turn and will be implemented.

%Need to explain these in a bit more detail
\subsubsection{Packet Metrics without Pre-filtering}

The first packet method technique discussed is \ac{TDEV}. It is used to specify network wander limits for timing signals and can also be used for packet data. 
\ac{TDEV} can be applied to both integrated and pre-processed packet selection methods. \\

The implementation equations are quoted in the reference. The approximation equations were used when implementing the functions. 

\subsubsection{\acf{TDEV}}
The basic TDEV equation has been given below, in Equation \ref{TDEVnorm}

\begin{equation}
\label{TDEVnorm}
TDEV(\tau) = \sqrt{\frac{1}{6n^2}\langle [\sum\limits_{i=1}^n (x_{i+2n} -2x_{i+n} + x_i )]^2 \rangle }
\end{equation}

Because of the angular brackets denoting an ensemble average sum, this would not be possible to be implemented. 
Therefore there's an approximation to this, given below in  Equation \ref{TDEVapprox}.
From now on any equations quoted will be in this approximate form.  

\begin{equation}
\label{TDEVapprox}
TDEV(n\tau_0) \equiv \sqrt{\frac{1}{6(N - 3n + 1)}\sum\limits_{i=1}^{N - 3n + 1} [x(i+2n) - 2x(i+n) +  x(i)]^2]} \\

for n = 1, 2, ... integer part (\frac{N}{3})
\end{equation}

The value in brackets next to $x$ denote the window that the particular selection method will be operating over. 
It has been assumed for this to mean that the window is weighted to 1, with the centre point in the window being the current point.
Therefore care will need to be taken when implementing these correctly. 
The mean of each of these windows will be taken. \\

The minTDEV uses the same approximation formula as above, but the minimum value is taken of th window instead of the mean. 
There are pros and cons for both of these metrics.
Firstly the minTDEV calculation is suitable for packet delay noise processes but not for frequency offset calculation \cite{ITUPacketMetrics}.
One downside however is that it is very sensitive to low lying outliers. \\

The next set of packet metrics discussed in the document was those based on the bandMean.
The bandMean is a mean calculating over a subset of the window size. 
An equation for this has been given below. 
\begin{equation}
x_{band\_mean}(i) = \frac{1}{m}\sum\limits_{j=a}^{b} x_j+1
\end{equation}

The approximation equation for this metric has been provided below. 

\begin{equation}
bandTDEV(n\tau0) \equiv \sqrt{\frac{1}{6(N - 3n + 1)}\sum\limits_{i=1}^{N - 3n + 1} [x_{band\_mean}(i+2n) - 2x_{band\_mean}(i+n) + x_{band\_mean}(i)]^2 } \\

for n = 1, 2, 3, ... integer part (\frac{N}{3})
\end{equation}

The last metric type used in this set was a percentile TDEV. 
This is very similar to the bandTDEV, but the value of a (the lower percentage) is set to 0. \\

\subsubsection{\ac{MATIE}}

The next set of packet metrics performed were \acf{MATIE} and \ac{MAFE}.
These are used to be able to analyse any time error of a set of packet delay . 
The estimation formula for \ac{MATIE} has been provided below. 

\begin{equation}
MATIE(n\tau_0) \equiv \max_{1\leq k \leq N - 2n + 1 }  \frac{1}{n} \arrowvert \sum\limits_{i=k}^{n + k -1} (x_{i+n} - x_i) \arrowvert \\

for n = 1, 2, ..., integer part (\frac{N}{2})
\end{equation}

To calculate the MAFE, the simple relationship below is used.

\begin{equation}
MAFE(n\tau_0) = MATIE(n\tau_0) / n\tau_0
\end{equation}

Same as before, these two metrics can also be used with the minimum packet selection type. 


\subsubsection{Packet Metrics with Pre-filtering}

The other method is using pre-filtering before the metric is calculated. 
An averaging function is applied to the set of data, but care must be taken to not over-filter the input.
This filtered packet sequence can then applied to the metrics mentioned previously in the report. 
Prefiltered metrics are useful as they can help specify network limits. \\

Note that these metrics weren't initially planned to be implemented, so the full explanation will not be added here.
Instead these can be found in the report \cite{ITUPacketMetrics}.


%Should a section on any other reading be added here?
\section{Project Methods}

Based on the objectives mentioned previously, the project can be split into some distinct sections:  

\begin{description}
\item[Data Collection] This part of the project will involve collecting \ac{PTP} timing data on the university network.
It will consist of using a number of different clock types and locations on the network.
\item[Packet Methods] This section will mainly involve the implementations of the packet metric scripts based on the referenced report above.
Focus on the implementation will be made in this section rather than the metrics themselves. 
\item[Calculating/Analysing Results] Once the metrics have been implemented fully, there needs to be some supplementary scripts written to process some of this data. 
\item[Clock Drift] It would be interesting to see how much the grandmaster clocks drift themselves over a long period of time.
\end{description}

There are some other topics that will be completed time permitting:
\begin{description}
\item[Securing PTP Considerations] As \ac{PTP} is inherently an unsecure system, there will be some work into investigating how PTP could be secured from rogue hosts on the network.
\item[Methods to reduce Packet Collisions] Due to the way Ethernet networks work, there is a high probability of packet collisions.  
Thus it would be useful to investigate, based on the results collected above, ways to reduce these packet collisions.

\end{description}

\section{Data Collection}

The first step to perform with this part of the project is to work out what hardware is available. 
The following hardware was identifed as being available to use for the duration of this project.

\begin{itemize}
\item Hardware Grandmaster - Chronos TimePort \cite{TimePort}
\item Hardware Slave - Chronos Syncwatch \cite{SyncWatch}
\item Hardware Slave - Beaglebone Black \cite{BBB}
\item Software Grandmaster - \ac{PTPd}
\item Software Slave - \acf{PTPd}
\end{itemize}

The above were identified to be suitable enough to carry out this project. 
If any assistance is required with the two Chronos hardware devices it will be possible to contact Chronos directly. 
\subsection{Hardware - Timeport \cite{TimePort}}

\subsubsection{Description} 

The Chronos CTL4540 Timeport is a low powered portable device that is able to maintain its time to a high accuracy when disconnected from a synchronisation source.
It is able to maintain accuracy within a couple hundred nanoseconds without needing to be connected to \ac{GPS}. 
It also has an internal LiPo battery. 
This enables the device to be used to transport and measure time without using an external power source.
Appendix \ref{app:TimePortSpec} shows the full specifications of the CTL4540 TimePort. 

With the above features in mind, it is thus suited for a number of markets, including the power industry and telecommunication network operators. 
It can also be used to correct for any time errors caused by any cabling or equipment. \\

Typical methods of doing this would originally have involved using a Caesium atomic clock or setting up a \ac{GPS} attenna and connecting this to some other equipment. 
The TimePort is best suited over these two operations because it is much lower power and much more transportable than an atomic clock.
It also removes the requirement of relying on \ac{GPS}.\\

%Below are a few labelled photos of the clock.

\begin{figure}
\centering
\begin{subfigure}{\textwidth}
	\centering
	\includegraphics[scale=0.5]{Figures/TimePort.eps}
	\label{TimePortOutside}
	\caption{Chronos TimePort Outside}
\end{subfigure}
\end{figure}
\begin{comment}
\begin{subfigure}{\textwidth}
	\centering
%	\includegraphics{Figures/TimePortInside.eps}
	\label{TimePortInside}
	\caption{Chronos TimePort Inside Block Diagram}
\end{subfigure}
\label{TimePortDiagrams}
\caption{Chronos TimePort Labelled Diagrams}
\end{figure}
\end{comment}
The difference between the release TimePort and the TimePort that will be used in this project is that the firmware on the TimePort is bleeding edge. 
With that in mind time needs to be allocated to allow for any issues that the clock may have or to update the firmware.
The university has close links with Chronos thus it should be straightforward to either get our issues solved or to receive a new TimePort. \\

This clock will mainly be kept in the same position on the network and will act as a Grandmaster. \\

In terms of documentation there is not much available for this device apart from some emails sent between Chronos and Dr Robert Watson. 
Therefore Appendix \ref{TimePortDocumentation} shows some documentation put together for my own use during this project. 
The documentation includes details on how to interface with the clock and a list of basic commands. \\

To access the device it needs to be accessed locally over a USB to Serial connection. 
\subsubsection{Using the Chronos TimePort}

The firmware version that the TimePort we have available does not have the control port active. 
Therefore the only method to connect to the TimePort is via a USB connection.\\

To connect to the TimePort: connect the USB cable and run the following command. 


\begin{lstlisting}[language=Bash, caption="Bash - Using Screen to connect to TimePort"]
screen /dev/ttyUSB0 115200, cs8, ixoff
\end{lstlisting}

This command sets the baud rate to 115200, and will connect you to the first layer of the TimePort. 
The system is a restricted linux distribution, so some commands you may be familiar with do exist.
A full list of commands and the rest of the documentation can be found in Appendix \ref{TimePortDocumentation}. 
%Figure \ref{fig:TP1stLayer} is a screenshot of this first layer

\begin{figure}
\centering
%\includegraphics[scale=0.5]{Figures/Screenshots/TimePortFirstLayer.eps}
\caption{TimePort Access}
\label{fig:TP1stLayer}
\end{figure}

% Need screenshots for this section
\subsection{Hardware - Chronos Syncwatch \cite{Syncwatch}}
\subsubsection{Description}
The Chronos Syncwatch is a hardware slave clock used to synchronise time in  a number of different applications.
It operates in all of the current synchronisation technologies such as SyncE, ESMC,  PTPv2, 1PPS+TOD, 1PPS, Frequencies(64k-200MHz), T1 \& E1 protocols and interfaces are supported. 
It can be used on both legacy and modern Ethernet/IP networks. 
It can simultaneously operate on a number of the protocols above. 
It can also operate in both local and remote modes. 
It is a small modular device with a simple user interface. 
It also integrates with with Symmetricom's TimeMonitor software. 
The device markets include telecommunications, TV and radio broadcasting, and the power industry. \\

The table shown in Appendix \ref{app:SyncwatchSpec} details the Syncwatch specifications. 
The figures below shows the outside panel of the device. \\


\begin{figure}[H]
\centering
	\centering
    \includegraphics[scale=0.5]{Figures/Syncwatch.eps}
	\label{SyncwatchOutside}
	\caption{Chronos Syncwatch Outside}
\end{figure}
\begin{comment}
\begin{subfigure}{\textwidth}
	\centering
%	\includegraphics{Figures/SyncwatchInside.eps}
	\label{SyncwatchInside}
	\caption{Chronos Syncwatch Inside}
\end{subfigure}
\label{SyncwatchDiagrams}
\caption{Chronos Syncwatch Labelled Diagrams}
\end{figure}
\end{comment}

This product is similar to the TimePort in the fact that it is an engineering release version therefore all of the features are not fully documented.
Therefore Appendix \ref{app:SyncwatchDocumentation} shows the documentation written up for the Syncwatch.\\

The Syncwatch will be mainly kept in the Level 3 Communications lab.
As this device is a release product, all of the ports used for controlling the device are enabled.
Therefore the Syncwatch can be set up via SSH or using the program. 

\subsubsection{Using the Chronos Syncwatch}

The device can be accessed using either ssh, serial, or through the Syncwatch-Lab program. 
As the first two stages are similar, these will be discussed at the same time.\\

\begin{figure}[H]
\centering
 \includegraphics[scale=0.5]{Figures/USB2Serial.eps}
\caption{USB to Serial Converter}
\label{fig:USB2Serial}
\end{figure}
To connect via ssh: log in using a terminal program using the following command:

\begin{lstlisting}[language=Bash,caption=SSH Command to Connect to the Syncwatch]
ssh root@eepc-rjw-syncwatch.bath.ac.uk
\end{lstlisting}

using password: $syncwatch$ .\\

This is the first Syncwatch layer. 
The alternative method to access this same terminal window is by using a USB to Serial converter, as pictured earlier, Figure \ref{fig:USB2Serial}.\\

Plug in the device to a computer, and connect to it using the following command:

\begin{lstlisting}[language=Bash, caption= Screen Command to Connect to the Device]
screen /dev/ttyUSB0 115200, cs8, ixoff
\end{lstlisting}

As before, the command sets the baudrate to 115200, and connects to the device using screen.

% This brings up the following prompt (shown in Figure \ref{Syncwatch1stLayer}. \\
\begin{figure}[H]
\centering
%\includegraphics[scale=0.5]{Figures/Screenshots/SyncwatchFirstLayer.eps}
\label{Syncwatch1stLayer}
\caption{Syncwatch First Layer Screen}
\end{figure}

To access the \ac{PTP} console, type the following:

\begin{lstlisting}[language=Bash, caption= Command to Access the PTP Console]
minicom -S
\end{lstlisting}

This then brings up the 2nd layer: the PTP console. 
The screenshot below (Figure \ref{Syncwatch2ndLayer} shows a list of commands available.
The complete list of commands in both of the modes is shown in the documentation, shown in Appendix \ref{app:SyncwatchDocumentation}. 

\begin{figure}[H]
\centering
%\includegraphics[scale=0.5]{Figures/Screenshots/SyncwatchSecondLayer.eps}
\caption{Syncwatch Second Layer Screen}
\label{Syncwatch2ndLayer}
\end{figure}

\subsubsection{Hardware - Beaglebone Black \cite{BBB}}
\subsubsection{Description}
The Beaglebone Black is a hardware device but it is running a software PTP Daemon (called PTPd). 
Throughout this report the Beaglebone Black will be called a hardware clock, but in reality it is running a \ac{PTP} software implementation. \\

The Beaglebone Black is a cheap development platform that runs Linux. 
In terms of hardware capabilities it has an ARM Cortex A-8 processor with 512MB of DDR3 RAM.
It runs a cut down version of Linux called Angstrom Linux.
It has Ethernet connectivity and runs off of a 5V DC supply.\\

As it runs Linux and can be connected to the network, an SSH server has been set up on it with a static IP address. 
This made it easy to start the PTP daemon. \\

Below (Figure \ref{fig:BBBLabelled} is a labelled picture of the BeagleBone Black.

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{Figures/BBB.eps}
\caption{Labelled BeagleBone Black \cite{BBBImg}}
\label{fig:BBBLabelled}
\end{figure}

The Beaglebone will be a useful device to use as a slave clock because of its portability.
It would be able to be placed anywhere on the network without any disruption to that particular lecture room or lab space.

\subsubsection{Using the Beaglebone Black}

To set up the Beaglebone Black:

\begin{enumerate}
\item Plug in the Beaglebone Black to the 5V adapter.
\item Plug in the Ethernet cable
\item Once the Beaglebone boots you can then access the device over SSH.
\end{enumerate}

Type:

\begin{lstlisting}[caption = SSH command to connect to the Beaglebone Black, language = Bash]
ssh <username>@eepc-rjw-beaglebone.bath.ac.uk
\end{lstlisting}

To log in, replace $<username$  with the username on the device. \\

The screenshot below (Figure \ref{SSH_To_Beaglebone}) demonstrates this.
The ls command was typed to show that the connection was successful.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/Screenshots/SSH_To_Beaglebone.eps}
\caption{SSH to Beaglebone}
\label{SSH_To_Beaglebone}
\end{figure}

Once SSH'd into the device, then the device can be accessed like any other linux machine.
Note however that there is a restricted command set \cite{AngstromInstructionSet}. 
When the BeagleBone boots, it was required that the SD card used to store the test data on would be automounted and that the PTP daemon automatically runs.
Several attempts in trying to automount the SD card using conventional means such as adding in an entry to fstab were attempted, but this did not work.\\

The method in getting round this was by creating a script in /etc/init.d. 
Any script located in that folder will automatically be loaded once the device boots. 
The PTP daemon was also run from this same script.
The script would also need to automatically name the data file or the data would be overwritten every time the device was turned on.
A convention of $timeport\_YYYY\_MM\_DD.txt$ was decided.\\

The full bash script is shown below, in Code Extract \ref{lst:bashBBB}

\begin{lstlisting}[label = lst:bashBBB, language = bash, caption=Bash Script in init.d for Beaglebone Black]
#!/bin/bash
mount /dev/mmcblk1p1 /mnt/sd
date=\$(date +"%Y_%m_%d")
sudo /home/eesrjw/ptpd2 -i eth0 -C -S -g -d 17 -V > /mnt/sd/eesrjw/timeport\_\$date.txt
\end{lstlisting}

Line 1 is the bash shebang which lets the operating system know that the following script is written in bash. 
The second line mounts the SD card to the correct location. 
In this case the SD card is device $mmcblk1p1$, and the mount location is /mnt/sd/.\\

The third line defines a date variable in Year\_Month\_Day format. 
The forth line runs the PTPd2 daemon. 
As the script is not saved in the PATH variable, the full path to the script is used. 
The flags will be discussed in more detail in the later section as similar flags will be used.\\

Once the script above is run (or if the PTPd2 script is run on its own from the terminal), the output is stored in the text file mentioned on Line 5.\\

Once the test is completed, the script can be killed by using $kill -9$ on ptpd2. 
The final step is to transfer the text file from the beaglebone to the local machine ready for packet metrics to be run on it. 

\subsubsection{Sending Data to the Local Machine}

There are two ways to retrieve the data from the Beaglebone: either pulling out the SD card and using an SD card reader to transfer the text file, or remotely using a utility such as $rsync$. \\

It was decided that as all other commands are sent to the device remotely, that a short rsync script will be made. 
Code Extract \ref{lst:rsync} below is the rsync script used. 

\begin{lstlisting}[language=bash, label = lst:rsync,caption=Rsync Script]
#!/bin/bash
echo "RSync List-only will run"
rsync --list-only jac50@eepc-rjw-beaglebone.bath.ac.uk:/mnt/sd/eesrjw/ ./
echo "Type filename here: "
read fileName
rsync -v --progress jac50@eepc-rjw-beaglebone.bath.ac.uk:/mnt/sd/eesrjw/i\$fileName ./NotSorted
\end{lstlisting}

The script above prompts the user to type in the filename. 
It lists the files in the correct directory on the beaglebone in case the user does not know the correct file name. 
Line 6 then performs the sync operation, using the verbose and the progress flag. \\

The only issue with this script is that it prompts the user twice for the password. 
As this script was not run very often it was not an issue.
If it was however more research would have been done to see if that could be fixed. 
A screenshot below (Figure \ref{fig:rsync} shows the rsync script transferring across a gzipped data file.

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{Figures/Screenshots/Rsync_From_Beaglebone.eps}
\caption{Rsync Example}
\label{fig:rsync}
\end{figure}

It was important to gzip the file beforehand or the transfer would have taken a lot longer. 
%--------------------------------------------------------------------------
The rate of data collection is around 10MB an hour. 
%--------------------------------------------------------------------------

\subsection{Software - \acf{PTPd}}

The final type of clock that can be used is a software daemon called PTPd (or sometimes PTPd2). 
It is a program written in C that meets most aspects of the IEEE1588 specification. 
PTPd2 meets the changes made in the 2008 standard.\\

In-depth code analysis of the script will not be provided in this report.
Instead the different flags that may be used for this project will be tabulated below (Table \ref{table:FlagsPTPd}).
The flags below were used throughout the project. 

\begin{table}[H]
\centering
\caption{Flags used for PTPd}
\begin{tabular}{|l|l|l|l|} \hline
\cellcolor{Black}\textcolor{White}{\textbf{Flag Name}} & \cellcolor{Black}\textcolor{White}{\textbf{Description}}  & \cellcolor{Black}\textcolor{White}{\textbf{Flag Letter V2.3.0 or above}} & \cellcolor{Black}\textcolor{White}{\textbf{Old Flag Letter}}\\ \hline
Interface & Network Interface to use & i & b \\ \hline
Domain & PTP Domain Number & d & i \\ \hline
Foreground & Run program in foreground &  C & C \\ \hline
Verbose &  Run in Verbose mode &  V & None \\ \hline
No Clock Adjust & Do not adjust the local clock & n & t\\ \hline 
Slave only mode &  Set PTPd as Slave &  s & g \\ \hline
\end{tabular}
\label{table:FlagsPTPd}
\end{table}

PTPd can be used as both a slave and a grandmaster.
As there is already a dedicated grandmaster, PTPd will be used mainly as a slave, but some software grandmaster clock tests may be performed.
The script call has already been given for the beaglebone. The code extract below has been used for the PTPd\_Netbook 

\begin{lstlisting}[language=bash,label=lst:ptpd2, caption = Running the PTPd Script]
./ptpd2 -C -S -g -i 17 -t | tee /home/james/FinalYearProject/PTPData/TestData/TimePort-To-Soft-Test4/RawData.txt
\end{lstlisting}

The difference in the call to ptpd2 above is that the command $tee$ has also been used so the data is displayed both on the screen and sent to the text file. 
An alternative method to this would be to redirect the standard output to the text file, then call $tail -f file\_name\_here$ to display the file in the terminal. 
This script can be run on any linux computer with root access with the script saved in the current working directory.
Note that the above script in Extract \ref{lst:ptpd2} is already run as a root user.
The other method to do this would be to run the script with sudo. 


\subsection{Data Collection Overview}
As the majority of the devices above will be controlled remotely via SSH, it would be useful for all of them to be on static IPs assigned by the university computing services. 
All devices were able to get a static IP with a domain forwarding in the format eepc-rjw-nameofdevice.bath.ac.uk. 
This is a local address which isn't forwarded outside of the university network. 
The summary table below shows what hardware is available, based on class, and IPs for the PTP port and the control port. 

\begin{table}[H]
\caption{Hardware Summary}
\label{table:hardwareSummary}
\begin{tabular}{|c|c|c|c|c|c|c|c|} \hline
\cellcolor{Black}\textcolor{White}{\textbf{Clock ID}} & \cellcolor{Black}\textcolor{White}{\textbf{Name}} & \cellcolor{Black}\textcolor{White}{\textbf{Type}} &  \cellcolor{Black}\textcolor{White}{\textbf{PTP IP}} & \cellcolor{Black}\textcolor{White}{\textbf{Control IP}}  & \cellcolor{Black}\textcolor{White}{\textbf{MAC Address}} \\ \hline
001 & Chronos TimePort & Hardware GM  &TimePort & USB over Serial & Unkown  \\ \hline
002 & Chronos SyncWatch & Hardware & syncwatchptp & syncwatch & 00:16:C0:17:20:A1 \\ \hline
003 & BeagleBone Black & Hardware & beaglebone & beaglebone & Unknown \\ \hline
004 & PTPd\_Desktop & Software &  Tesla & N/A & N/A \\ \hline 
005 & PTPd\_Netbook & Software & N/A & N/A & e8:9a:8f:97:64:13 \\ \hline
\end{tabular}
\end{table}

The clock ID was used with internal documentation to know which clock was used where. 
Note that the domains listed in the table are just part of the full domain name. 
To access one of them on the university network, add the prefix eepc-rjw- and the suffix .bath.ac.uk.
For example, to access the Beaglebone the address is eepc-rjw-beaglebone.bath.ac.uk. 



\subsection{Locations for Clocks}

To get a varied set of data points, it was decided to collect data at a number of locations throughout the network. 
The following locations were identified, along with some information on the surroundings.

\begin{table}[H]
\caption{Clock Locations}
\label{table:clockLocations}
\begin{tabular}{|c|c|c|c|c|} \hline
\cellcolor{Black}\textcolor{White}{\textbf{Clock Location}} & \cellcolor{Black}\textcolor{White}{\textbf{Room number}} & \cellcolor{Black}\textcolor{White}{\textbf{Room Type}} & \cellcolor{Black}\textcolor{White}{\textbf{Left Unattended}} & \cellcolor{Black}\textcolor{White}{\textbf{Distance from Grandmaster}} \\ \hline
Watson's Office & 2E 4.6 & Office & Locked office & Same room \\ \hline
2\textsuperscript{nd} floor lab & 2E 2.10 & Lab & Secure lab & Same subnet \\ \hline
Comms Lab & 2E 3.14 & Lab & Secure & Same subnet \\ \hline
Library & Library & Library & No. Busy 24/7 & Different subnet \\ \hline
8W Rooms & 8W 2...& Lecture room & No & Different subnet \\ \hline
East building & EB 2.. & Lecture room & No & Different subnet \\ \hline
\end{tabular}
\end{table}

The locations above and in the diagram below (Figure \ref{UniMap}) are only examples of possible locations. 
Due to getting access to rooms or the possibility of PTP not been transmitted out of the particular subnet it may not be possible to use some of the rooms listed above. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/UniMap.eps}
\label{UniMap}
\caption{University Map}
%\caption{University Map with clock locations labelled}
\end{figure}

A broad range of locations were attempted, within the limitations of the network. 
Connecting via a VPN was attempted but it was deemed that the \ac{PTP} packets were not transmitted outside of the network and thus were not suited for the job.
A network topology map has also been added, see below Figure \ref{NetworkMap}. 

\begin{figure}[H]
\centering
%\includegraphics[scale=0.5]{Figures/NetworkMap.eps}
\caption{Network Topology Map}
\label{NetworkMap}
\end{figure}

% Any discussion here
\subsection{Test Sheets}

As there will be several tests performed during the project, and it is important to note times and locations of each test, a test sheet has been created using LibreOffice Calc. An example of a test sheet is found in Appendix \ref{app:testsheet} \\

Each test sheet will have the following:

\begin{description}
\item[Test ID] Each test gets a unique ID number. 
The number increments for every test performed. 
\item[Test Name] A general name for the test. 
This usually consists of the GM clock type, the slave clock type, and the number associated with that type of test. 
\item[Test Date] The date at which the test was performed in ISO 8601 format.
\item[File Name] The file name for the test file.
If the test has to be stopped for any reason, a new file is made with a number at the end. 
The file name is typically RawData.txt. 
\item[Directory] The directory where the test data is stored.
\item[Clock Type] Each clock will have its clock type listed. 
The clock types have been mentioned earlier in this report. 
\item[Clock Name] The name of the clock. 
This is a unique identifer in case multiple clocks of the same type and model are used. 
\item[Clock Model] The model of the clock. 
\item[Start Time] The time that the test started. 
This is as accurate as possible so network data can be correlated with it. 
\item[End Time] The time that the test finishes. 
If the test is stopped prematurely but started up again, the final end time is noted here, but the intermediate start and stop time is listed in the comments section.
\item[Network Activity] An average network activity for the day (low, medium, high). 
This is used to correlate delay spread with network activity.

\item[Test Description] Brief description of why the test was performed and what the expected outcome of the test is.
\item[Comments] Any comments can be noted here. Start/Stop times, or if any issues come up will be noted here.
\end{description}


All of the test sheets will not be shown in this report, but the information has been compiled into a summary test sheet.
The summary sheet (Appendix \ref{app:SummaryTestSheet})will include the Test name, date, directory, and start and end times of the tests. 

\subsection{Testing Schedule}

This part of the project will run in parallel with the implementation stage of the packet metrics, as this does not rely on them being completed. 
The tests that are to be completed will include:

\begin{itemize}
\item Hardware to Hardware
\item Hardware to Software
\item Hardware to Beaglebone
\item Different locations
\item Different Times
\end{itemize}

An explicit testing schedule has not been produced, but the full list of tests that would like to be completed have been listed below. 
Instead there are week blocks allocated in the gantt chart for data collection, and tests will be carried out throughout that time.\\

The following tests that have been identified as important tests to run have been included in the table below.

\begin{table}[H]
\caption{Some Tests to Run}
\begin{tabular}{|c|c|c|c|c|}\hline	
\cellcolor{Black}\textcolor{White}{\textbf{GM Clock Type}} & \cellcolor{Black}\textcolor{White}{\textbf{GM Clock Location}}  &\cellcolor{Black}\textcolor{White}{ \textbf{Slave Clock Type}} & \cellcolor{Black}\textcolor{White}{\textbf{Slave Clock Location}} & \cellcolor{Black}\textcolor{White}{\textbf{Duration}} \\ \hline
Hardware (TimePort)  & Watson's Office & Hardware (Syncwatch) & 2E 3.Comms lab & 24 hours \\ \hline
Hardware (TimePort) & Watson's Office & Software (PTPd) & Watson's Office & 24 hours \\ \hline
Hardware (TimePort) & Watson's Office & Software (PTPd) & 2E 2... Lab  & 24 hours \\ \hline
Hardware (TimePort) & Watson's Office & Beaglebone  & Anywhere available& 24 hours \\ \hline
\end{tabular}
\end{table}

Any other tests may also be performed, including but not limited to: different grandmaster clock types and for different durations.

\subsection{Data Processing}

The final section of this part of the project consisted of initially processing the data that is gathered from the various clocks mentioned above.
This is important because certain parts of the data is only needed for certain metrics and can thus be reduced to reduce the overall memory usage of the scripts.

\subsubsection{Example Data File}

An example file output for the PTPd implementation which is run on the majority of the clocks is shown below in Figure \ref{FileOutput}.  

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/Screenshots/ExampleData.eps}
\caption{Example of the File Output}
\label{FileOutput}
\end{figure}

This data is formatted as a \ac{CSV} filetype of the following format: 

\begin{description}
\item[Timestamp] The timestamp includes the big-endian date format specified under ISO 8601 as well as the time. 
The time is displayed in an HH:MM:SS.\#\#\#\#\#\# type format, with the hashes denoting the decimal after the seconds field.
\item [State] The state is what state the clock is in, for example a Grandmaster or a Slave. 
\item[Clock ID] The clock ID is a hardware ID which is specified under IEEE1588. 
\item[One Way Delay] The one way delay is the average of the Master to Slave and Slave to Master delays. \cite{PTPM2S}. 
\item[Offset from Master] This is the difference between the master clock timestamp and the current slave clock timestamp.
\item[Slave to Master] This is the propagation delay from Slave to Master. 
\item[Master to Slave] This is the propagation delay from Master to Slave. 
\item[Drift] This refers to the drift of the slave clock relative to the grandmaster. 
It is unclear exactly what this number is though since it is an integer. 
\item[Last Packet Received] This is a single character which is the type of packet received. 
For example, S is a sync packet, and D is a delay packet.
\end{description}

\subsubsection{Script to Parse the Data File}

It can be seen that depending on what calculation is performed, there is quite a bit of excess data not required. 
Assuming that there will be 32 of these messages every second, the RAM requirement will be high if a long test was performed.
Therefore it was decided to create a script that would parse this data into a correct form for use later on.
Even with the data parsed, there may be too many data points. 
Thus a method to average the data by an arbitary value will also be added into this script.\\

Because this was a preprocessing step, it is important to try and keep the execution time of this script as low as possible. 
Due to the script having to operate on a line by line basis, it was decided to use the scripting language Awk \cite{awk}.\\

Awk has several advantages over other similar tools, but its main strength is that it is a very useful and efficient tool in parsing rows and columns of log files\cite{awkAdvantages}.
It can perform operations on a line by line basis, or when certain conditions are met (for example every N lines, or at the start and end of the file). 
Because it is used for file parsing, it has a built in regular expression engine which is handy for string manipulations. 
Its simple structure makes it a suitable tool for the job. 
It was also identifed to be a useful tool to know in the future, and thus it was decided to use awk for this part of the project.\\

\paragraph{Flow Chart}

The script needs to be able to: read in the text file, save the correct columns to a new file.
If appropriate the script should also average N number of data points and save these to the new input file instead.
The time field must also be parsed correctly and the time delta added to the new file. \\

The general script layout has been converted to a flow chart, see below Figure \ref{FC:AwkScript}.
\begin{tikzpicture}[framed, node distance = 2.5cm, auto, thick,scale=0.6, every node/.style={scale=0.6}]
    % Place nodes
	\node [block] (init) {Start Script};
	\node [block,right of =init] (inputargs) {Check any Input Arguments};
	\node [block,right of =inputargs] (initvars) {Initialise FS and any other variables};
	\node [decision, right of=initvars] (everyline) {New line of file to read?};
	\node [decision,  right of=everyline] (NR3){If Line Number is less than 3};
	\node [block, right of=NR3] (inccount) {Increment Counter};
	\node [block, right of=inccount] (calctime) {Calculate the time delta};
	\node [block, right of=calctime] (print) {Print time delta and delay data};
	\node [block, right of=print] (reset) {Set variables to 0};
	\node [block, down of=everyline] (finish) {End};


    % Draw edges
	\path[line] (init) -- (inputargs);
	\path[line] (inputargs) -- (initvars);
	\path[line] (initvars) -- (everyline);
	\path[line] (everyline) -- (NR3);
	\path[line] (NR3) -- (inccount);
	\path[line] (inccount) -- (calctime);
	\path[line] (calctime) -- (print);
	\path[line] (print) -- (reset);
	%\draw[->] (reset.south) -| ($(reset.south)!0.5! (everyline.west)$) -| (everyline.west);
    \draw[->] (reset.south) -| everyline.west;
	\draw[->] (NR3.north) -| ($(NR3.north)!0.5! (everyline.west)$) -| (everyline.west);


\end{tikzpicture}

This flowchart was then used to create the awk script, shown in Appendix \ref{app:awkscript}. 
Most of the code is self documenting, but the $add\_time$ will be explained as that was part of the code that required some extra work to get working correctly.

\paragraph{\textbf{add\_time} function}

The role of this function was to amalgamate the times from the first sample to the Nth sample, with N being the size of the window.
The main issue with this function was the formatting of the time itself as it was not either an ISO 8601 float nor in the correct format for an inbuilt function $mktime$ to be called.
Therefore the following steps were performed to convert the time to the correct format. 

\begin{enumerate}
\item \textbf{Regex:} Before the function is called, a regular expression substitution is used to replace all colons with spaces and all dashes to spashes. This was important because the end goal is to convert the current time format into one seperate by spaces. 
\item \textbf{Split Seconds portion by full stop:} This step would parse the milliseconds away from the seconds.
\item \textbf{Compare the delta times to see if one was bigger than the other:} This was important so the correct sign of the delay was used.
\item \textbf{Calculate delta:} This is used to determine the size of the time deltas.
\end{enumerate}

This script was tested quite thoroughly to make sure all of the cases were covered, but this was not fully documented.
 
\paragraph{Conclusion to the Script}

The script runs very quickly, primarily due to the correct choice in language early on.
Any testing for this script was carried out before it was integrated into any other source file.
It was important to try and keep this script standalone, so any data file can be parsed independently without needing to call an extra program.\\

The following table shows some execution times for this part of the script given the number of lines run on a netbook.
The above results were taking with a 10point average. 

\begin{table}[H]
\centering
\caption{Execution Times for Awk Script}
\begin{tabular}{|l|l|} \hline
\cellcolor{Black}\textcolor{White}{\textbf{Number of Lines}} & \cellcolor{Black}\textcolor{White}{\textbf{Time (ms)}}  \\ \hline
1000 & 7 \\ \hline
10000 & 28 \\ \hline
100000 & 1384 \\ \hline
1000000 & 14145 \\ \hline
\end{tabular}
\end{table}

Based on the table above, the script is suitable enough considering that this will only be run once then the file is saved. 
\section{Packet Methods}

This section of the project is the bulk of the programming development.
Packet metrics will be created in a suitable language and will be run against the data collected in the previous section.\\

A range of packet metrics were chosen to be implemented from the report detailed in the literature review section of this report. 
The following packet metrics will be implemented: TDEV, minTDEV, percentileTDEV, bandTDEV, MATIE, and MAFE. 
Note that both MATIE and MAFE can have different packet selection methods (min, percentile, or band), so there may be more than the above implemented in the final script. 

\subsection{Choosing a Suitable Language}

The first decision to make for this section of the project was to choose a suitable programming language. 
Based on the languages that would be suitable for a task such as this, the following languages were identified: R, C, Matlab, or Python. \\

The requirements that the language must meet in order to be suitable for the project are listed below.\\

\begin{description}
\item[REQ1- Familiarity with the Language] \hfill \\ \textit{Spec: Used for a sufficient length of time} \\ If the language was very familiar the development time of the scripts would be quicker. 
This extra time may be acceptable however if there is a much better language ssuited for the task. 
\item[REQ2 - Well Documented] \hfill \\ \textit{Spec: Not Applicable} \\ The majority of modern high level languages are well documented, with some online resources better than others. 
The language must be well documented. 
This will also make it easier if \textbf{[REQ1]} has not been met fully as it would be easier to learn the language with good documentation. 
\item[REQ3 - Plotting Functionality] \hfill \\ \textit{Spec: Sufficient plotting functionality available to meet the task} \\ 
The language must have enough functionality to be able to plot the data gathered in several different forms. 
\item[REQ4 - External libraries already available] \hfill \\ \textit{Spec: All available} \\ Some external libraries may be needed in case some specific functionality is required. Examples of external libraries that will be required are a command line argument tool and logging functionality.  
\item[REQ5 - Speed] \hfill \\ \textit{Spec: Performs the metrics in a reasonable length of time} \\ The metrics should be able to run on a relatively large dataset in a reasonable length of time.
As it is unknown how long the scripts will take, this reasonable length of time will be decided later.
If need be optimisation can be made to make the scripts faster.
\item[REQ6 - Linux Compatibility] \hfill \\ \textit{Spec: Can be developed under Linux} \\ As the rest of the development will be using a Linux Mint netbook, it is a preference for the language to be suitable for a Linux development environment.

\end{description}
To decide on the best solution, a set of ranking criteria was created as well as a ranking table. 
The table below shows the criteria that the above languages were compared against. 
\begin{table}[H]
\centering
\caption{List of Criteria for the Language Options}
\begin{tabular}{|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{2cm}|c|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{3cm}|}\hline
\cellcolor{Black}\textcolor{White}{\textbf{Criterion}} & \cellcolor{Black}\textcolor{White}{\textbf{Description}}& \cellcolor{Black}\textcolor{White}{\textbf{Requirement}} & \cellcolor{Black}\textcolor{White}{\textbf{Weight}} & \cellcolor{Black}\textcolor{White}{\textbf{Highest - 5}} & \cellcolor{Black}\textcolor{White}{\textbf{Lowest - 0}}\\ \hline
Familiarity with the Language & Is the engineer familiar with the language syntax and style? & \textbf{[REQ1]} & 9 & Developed a few large projects. & No familiarity \\ \hline
Plotting functionality & What plotting functionality is available for the language& \textbf{[REQ3]}& 8 & Lots of plotting functionality & All plotting functions would need to be written from scratch \\ \hline
External Libraries available & Are all of the libraries available to complete the project? & \textbf{[REQ4]} & 7 & All of the required libraries are available. & Minimal library support. \\ \hline
Speed & Is the chosen language going to be fast enough for the application? & \textbf{[REQ5]} & 7 & Fast enough. & Not fast at all. Needs careful programming to make as efficient as possible. \\ \hline
Linux Compatibility & Is the language compatible in a linux development environment?  & \textbf{[REQ6]} & 7 & Yes, it is compatible. & No. Windows Only \\ \hline
Development Time & How long would it take to develop the first program & \textbf{None} & 7 & Less than a month & Longer than 3 months \\ \hline
 Documentation & Is the language mature enough to have a full set of documentation? & \textbf{[REQ2]} & 6 & Yes. The language has clear and concise for all of the documentation. & Very limited. \\ \hline
\end{tabular}
\end{table}

% ---------------------------------------------------------------------
\begin{table}[H]
\caption{Language Options Ranking Tables}
\label{table:lang}
\centering
\begin{tabular}{|c|c|m{2cm}|m{2cm}|m{2cm}|} \hline
\multicolumn{5}{|l|}{\cellcolor{black}\textcolor{white}{\textbf{Programming Language}}} \\ \hline
\multirow{2}{*}{Ranking Criteria} & \multirow{2}{*}{Weight} & \multicolumn{3}{|c|}{Language} \\ \cline{3-5}
& & R & Matlab & C \\ \hhline{*{5}{|-}}
Familiarity with the Language & 9 & \cellcolor{OrangeRed}{9} & \cellcolor{Goldenrod}{36} & \cellcolor{ForestGreen}{45} \\ \hhline{*{5}{|-}}
Plotting Functionality & 8 & \cellcolor{ForestGreen}{40} & \cellcolor{Goldenrod}{32} & \cellcolor{Red}{0} \\ \hhline{*{5}{|-}}
External Libraries Available  & 7 & \cellcolor{ForestGreen}{35} & \cellcolor{Goldenrod}{21} & \cellcolor{Orange}{14} \\ \hhline{*{5}{|-}}
Speed & 7 & \cellcolor{Orange}{14} & \cellcolor{Orange}{14} & \cellcolor{ForestGreen}{35} \\ \hhline{*{5}{|-}}
Linux Compatibility  & 7 & \cellcolor{ForestGreen}{35} & \cellcolor{Goldenrod}{21} & \cellcolor{ForestGreen}{35} \\ \hhline{*{5}{|-}}
Development Time & 7 & \cellcolor{Orange}{21} & \cellcolor{ForestGreen}{28} & \cellcolor{OrangeRed}{14} \\  \hhline{*{5}{|-}}
Documentation & 6 & \cellcolor{ForestGreen}{30} & \cellcolor{ForestGreen}{24} & \cellcolor{Orange}{12} \\ \hhline{*{5}{|=}}
\multicolumn{2}{|r|}{\textbf{Total Figure of Merit}} & \cellcolor{ForestGreen}{\textbf{184}} & 176 & 155 \\ \hhline{*{5}{|-}}
\end{tabular}
\end{table}

Therefore based on the ranking table above it was decided that R will be the most suitable language for the task.
In addition to this there are some R scripts as part of the PTPd which may also be used if suitable.\\

R is a programming language that used primarily for statistical computing. 
It is similar to the S programming language but under the \ac{GNU} umbrella.
R has many strengths in statistics due to the wide range of libraries available to it.
In addition to this it has extensive plotting functionality, both as standard and those written by third parties.
For computationally difficult tasks functions can also be ported into C, C++, or Fortran.\\

The development environment used for this project will be between a Linux Mint netbook and a virtual machine running Debian.
A standard text editor (vim) and R will be used to run the scripts, rather than using a full \ac{IDE} such as R-Studio.
Note that the code will be written so it can run cross platform, provided that the necessary libraries have been installed.

\subsection{General Packet Metric Implementation}

The packet metric literature review section of this report ( Section \ref{metricReview}) outlines the equations used to calculate the metrics.
It can be seen from these different metrics that there is a common format for all of them, and this will be exploited where possible.\\

Each of the packet types will be performed in the smallest number of for loops as possible to cut down on execution time.
The general format for the packet metric script in a flowchart is the following (Figure \ref{flowchart:General})

\begin{figure}[H]
\centering
\label{flowchart:General}
\begin{tikzpicture}[framed, node distance = 2.5cm, auto, thick,scale=0.6, every node/.style={scale=0.6}]
    % Place nodes
	\node [block] (initvars) {Initialise all required variables};
	\node [decision, right of=initvars] (forloop) {Loop from 1 to Limit};
	\node [block, right of=forloop] (initstep) {Set temporary variable to 0};
	\node [block, right of=initstep] (metric){Compute the Metric step and save to a temporary variable};
	\node [block, right of=metric] (squarevar) {Square the temporary variable};
	\node [block, right of=squarevar] (save2result) {Save temporary variable to result};
	\node[block, right of=save2result] (division) {Divide result by quotient};
	\node[block,right of=division] (squareResult) {Take the squareroot of the result};
	\node[block,right of=squareResult] (return) {Return the Result};

    % Draw edges
	\path[line] (initvars) -- (forloop);
	\path[line] (forloop) -- (initstep);
	\path[line] (initstep) -- (metric);
	\path[line] (metric) -- (squarevar);
	\path[line] (squarevar) -- (save2result);
	\path[line] (save2result) -- (division);
	\path[line] (division) -- (squareResult);
	\path[line] (squareResult) -- (return);
	\draw[->] (save2result.south) -| ($(save2result.south)!0.5! (forloop.south)$) -| (forloop.south);

\end{tikzpicture}
\caption{General Packet Metric Flowchart}
\end{figure}

The flow chart above has been converted into psuedo code, seen below.\\

\begin{algorithm}[H]
\SetKwFunction{TDEV}{TDEVAllMethods}%
\Fn{\TDEV{To , n , N , x ,a ,b}}{ \\
\KwData{window \tcc{ Sets the windowSize} \\
	InterimStep \\
	X}
\KwResult{result}
Initialise all required variables to 0\;
\For (Loop from 1 to the end of the summation) {1 to end of summation}{
Set inner step value to 0\\
Calculate Metric;\\
interimStep = interimStep * interimStep\\
result += interimStep\\
}
result = result / (6 * N - (3*n) + 1) \\
result = sqrt(result)\\
return(result)
}\\
\caption{Psuedo-Code for General Packet Metric Script}
\end{algorithm}

The for loop length is determined by the value of $N$ (the number of samples) and $n$ (the current iteration in the set). 
Note that the algorithm designed above only calculates one result for the particular packet metric.
This function would have to be called continuously with an incrementing value of $n$ up to the limit. 
This limit is determined by the particular metric and has been discussed in the previous section.\\

Because the TDEV and MATIE packet metrics have different looping conditions, they will be created in two seperate scripts, as discussed in the later sections. 
\subsection{TDEV and TDEV derivatives}

Using the above flow chart as a base for the script, the TDEV and derivative functions were created.
All of the TDEV scripts will be created in one source file in R. \\

The four metrics that will be implemented were: TDEV, MinTDEV, BandMeanTDEV and PercentileTDEV. 

\begin{description}
\item [TDEV] The TDEV script requires that mean values are taken of each individual window. 
As there is a built in mean function to R, this will be used.
Optimisation of this mean algorithm will not be looked into.
\item [minTDEV] Same as above, as a minimum function exists in R, this function will not be written directly. 
\item [bandMeanTDEV] A band mean is similar to a mean but is taken over a particular set of values of the window. 
For example, if the band mean was taken between 20 and 80\%, then the mean will use the middle 60\% of values. 
As this function does not exist in R, this would have to be created.\\

The bandMean implementation can be found below, in Code Listing \ref{code:bandMean}. 
This can also be found in Appendix \ref{app:bandMean}.

\lstinputlisting[caption=Band Mean Implementation, label=code:bandMean, language=R]{../PacketMetrics/bandMean.r}

The script converts the bands $a$ and $b$ into an integer. 
If the window size was 5, and $a$ was 0 and $b$ was 100 (i.e the total window size), then a would be 1 and b would be 5. 
The sum is the computed by looping from a to b. 
The average is then taken by divided the sum by $b - a + 1$.\\

\item[percentileTDEV] The percentileTDEV is very similar to the bandTDEV, except that the lower band is forced to 0. 

\end{description}

With these four packet types, and referring to the general form of the script in the previous section, the complete TDEV script can be produced. 
See Appendix \ref{app:TDEVAll} for the full implementation of the script in R.


\subsection{MATIE and MAFE derivatives}

The MATIE and MAFE derivatives were created in a similar method to the TDEV scripts above, but the main difference is both for loops have different upper bounds, hence why a different script needed to be created.
The following MATIE and MAFE packet metrics were used: MATIE, MinMATIE, MAFE, and MinMAFE. 

\begin{description}
\item[MATIE] This is implemented in a similar fashion to TDEV, using the built in mean function.
\item[minMATIE] The built in minimum function was used for this metric, in a similar method to the minTDEV script.
\item[MAFE] As described previously, MAFE is very similar to MATIE but there's a scaling value. 
Therefore only 2 values will be produced in this function, then MAFE will be calculated at the end before the values are returned. 
\item[minMAFE] This will be calculated based off of the minMATIE result.
\end{description}

The MATIE/MAFE script was then created, which can be found in Appendix \ref{app:MATIEAll}. 
\subsection{Overall Packet Script}

Once the packet metric functions were created, these will need to be both called from a seperate file which will handle file IO and plotting.
The following is a list of functions that the overall script should perform:

\begin{description}
\item[Input Arguments] For the script to be fully functional, the script must be able to accept input arguments. 
\item[Logging] The script may end up taking quite a bit of time to compute the packet metrics. 
Therefore some functionality of logging must be built in to this script.
The logs may also be saved to a text file if needed.
\item[Writing to a File] To save from calculating the same packet metric data for a particular data set, the results can be saved to a text file.
\item[Plotting] The script must have some plotting functionality, as that is how the data will be displayed.
\end{description}

\subsubsection{Flow Chart}


The general layout of the script will be discussed, then each relevant function will then be discussed in turn. 
The flow chart for this script can be seen below, in Figure \ref{flowchart:overall}. 
With the following flowchart, there are some decisions to be made on what libraries to use and how to go about implementing certain functions.

\begin{figure}
\centering
\begin{tikzpicture}[framed, node distance = 2.5cm, auto, thick,scale=0.6, every node/.style={scale=0.6}]


	\node[block] (loadLib) {Load Libraries and other Scripts};
	\node[block,right of=loadLib] (initvars) {Initialise variables};
	\node[block,right of= initvars] (parseArg) {Parse the Arguments and validate them};
	\node[decision,right of =parseArg] (loop) {For every test};
	\node[block, right of =loop] (filename) {Parse the correct file name and load};
	\node[block,right of=filename] (read) {Read and purge the delay data};
	\node[block,right of =read] (plotDelay) {Plot the delays};
	\node[block,right of =plotDelay] (metric) {Calculate Metrics};
	\node[block,right of =metric] (plotMetric) {Plot the metric data};
	\node[block, right of =plotMetric] (save) {Save the data to a new file};
	\node[block,right of =save] (end) {End the Script};


	\path[line] (loadLib) -- (initvars);
	\path[line] (forloop) -- (parseArg);
	\path[line] (parseArg) -- (loop);
	\path[line] (loop) -- (filename);
	\path[line] (filename) -- (read);
	\path[line] (read) -- (plotDelay);
	\path[line] (plotDelay) -- (metric);
	\path[line] (plotMetric) -- (save);
	\path[line] (save) -- (end);
	\draw[->] (save.south) -| ($(save.south)!0.5! (loop.south)$) -| (loop.south);

\end{tikzpicture}
\caption{Overall Packet Script Flow Chart}
\label{flowchart:overall}
\end{figure}

\subsubsection{Input Arguments}

It was intended for this packet metric script to be fairly comprehensive. 
Thus it would require input arguments so the user can choose what sort of metric to perform or on which set of data.
The input argument functionality for R is similar in some respects with C: it only consists of positional arguments and uses an argc / argv type structure.
It would be better to use a more substantial input argument library such that optional flags can also be used.\\

Argparse \cite{argparse}, a library originally written for Python but ported to R, was the most suitable choice. 
It has numerous useful features such as it generates a help command automatically and allows for the use of optional flags.\\

The next decision would be to see what arguments would be required. 
The following table outlines what arguments were used.

\begin{table}[H]
\caption{List of Arguments}
\begin{tabular}{|l|p{4cm}|l|l|l|l|} \hline
\cellcolor{Black}\textcolor{White}{\textbf{Argument Name}} & \cellcolor{Black}\textcolor{White}{\textbf{Description}} & \cellcolor{Black}\textcolor{White}{\textbf{Argument Flag}} & \cellcolor{Black}\textcolor{White}{\textbf{Type}} & \cellcolor{Black}\textcolor{White}{\textbf{Default Value}} & \cellcolor{Black}\textcolor{White}{\textbf{Destination}} \\ \hline
Test Number & Which test number should be used? & -nTest & Integer & - 1 & nTest \\ \hline
Number of Lines & How many samples should be used? & -nLines & Integer & 0 & nLines \\ \hline
Directory & What is the test directory? & -directory & String & None & directory \\ \hline
Metric & What metric type do you want to run? & -metric & String & TDEV & metrics \\ \hline
Direction of Delay & Do you want Master to Slave or Slave to Master & -delayDir & String & Master2Slave & direction \\ \hline
% Leave blank, as the code can be amended
CSV File & Do you want to save the data in a CSV file? & -CSV & Boolean & None & CSV \\ \hline
Verbose Mode & Do you want the logging to be verbose? & -v --verbose & Boolean & None & verbose \\ \hline
Quiet Mode & Do you want the logging to be quiet? & -q --quiet & Boolean & None & quiet \\ \hline
Histogram & Do you want a delay histogram saved? & --hist & Boolean & None & hist \\ \hline
Colour Histogram & Do you want a colour delay histogram saved? & --cHist & Boolean & None & cHist \\ \hline
Delay Plot & Do you want the delay plotted? & --plotDelay & Boolean & None & pdelay \\ \hline
Statistics & Do you want to generate a table of Stats? & --stats & Boolean & None & stats \\ \hline
Starting Point & Set the starting point of the test data & --start & Integer & 0 & start \\ \hline
Interactive Mode & Enable Interactive Mode & -i & Boolean & None & interactiveMode \\ \hline
\end{tabular}
\label{arguments}
\end{table}

All of the arguments above have been implemented as optional, but there is some logic to work out which ones are required. 
The following flowchart explains the logic that the parsing argument function goes through in order to check if everything is valid.

\begin{figure}[H]
\centering
\begin{tikzpicture}[framed, node distance = 2.5cm, auto, thick,scale=0.6, every node/.style={scale=0.6}]

\node[block] (parseArgs) {Parse Arguments into Array};
\node[decision,right of=parseArgs] (inter) {Interactive?};
\node[block,south of=inter] (runInt) {Run Interactive};
\node[decision,right of=inter] (dirDelay) {Check if Dir or Delay = None};
\node[decision,south of =dirDelay] (ifError) {If Error};
\node[block,south of =ifError] (Stop) {Stop};
\node[decision,right of =dirDelay] (SSValid) {Is SampleSize Valid?};
\node[block, south of =SSValid] (SetTo50) {Set SS to 50};
\node[decision,right of =SSValid] (StartNot0) {If Starting Point != 0};
\node[block, south of =StartNot0] (SetStart) {Set Start Point};
\node[decision,right of =StartNot0] (SampleSize) {All SampleSize Test?};
\node[block, down of=SampleSize] (SetSize) {Set Size and Test Nunbers};
\node[block, right of=SampleSize] (SetTest) {Set Tests to NTest};
\node[block, right of=SetTest] (Stop) {Stop};


\end{tikzpicture}
\end{figure}

The flow chart above was implemented in the main packet metric script as well as some of it ported to another function.


\subsubsection{Logging}

Due to the large number of functions and steps that the script has to perform (and possibly a long execution time), it was paramount that a suitable logging system was set up such that any issues can be tracked.
This can also be used so the user can know which section the script is currently working on.
A simple custom made system could have been made which just had different print messages depending on the logging level, but due to range of 3rd party libraries available for R, a logging library was used.\\

Similar with ArgParse, the logging library \cite{logging} was based off of the logging library for Python. 
The library is thread safe and has a number of different logging levels.
One useful feature is that it can have multiple loggers which will direct output to the console and/or a text file depending on the level of the logging entry.\\

The code extract below (Code Extract \ref{code:logging}) details the steps to initialise the logger.
Once initialised a logger entry can be written using one of the functions detailed in the documentation.

\begin{lstlisting}[language=R, caption=Setting up Logger, label=code:logging]
	if (args$verbose == TRUE) {
		basicConfig(level=10)
		loginfo("Verbose mode activated")
	} else if (args$quiet == TRUE) {
		basicConfig(level=30)
		loginfo("Quiet mode activated")
	} else {
		basicConfig(level=20)
	}	
	addHandler(writeToFile,file="LogFiles/Test.Log",level=10)
	loginfo("-------------------------------------------------")
	loginfo(" ---------- PacketMetric.R Log ------------------")
	loginfo("-------------------------------------------------")


\end{lstlisting}

Based on the input arguments the logging level is set to either 10 or 30, and a filehandler is added. 
The following logging messages were used throughout the Packet Metric Script.

\begin{table}[H]
\caption{Logging Entries}
\begin{tabular}{|l|l|l|l|} \hline
\cellcolor{Black}\textcolor{White}{\textbf{Logging Entry Name}} & \cellcolor{Black}\textcolor{White}{\textbf{Level}} & \cellcolor{Black}\textcolor{White}{\textbf{Type}} & \cellcolor{Black}\textcolor{White}{\textbf{Description}} \\ \hline
Header  & Info & General & Header for the Log File \\ \hline
Script Loading & Info & Libraries & Notifies when all libraries have loaded successfully \\ \hline
Init Logger & Info & Logger & Initialises the Logger \\ \hline
Interactive Menu & Info & Interactive Menu & Notifies when the interactive menu has been activated. \\ \hline
Directory / Test No. & Error & Parse Args & Error thrown when no directory or test number is found. \\ \hline
Sample Size Changed & Warning & Parse Args & Warning when the sample size has been changed to 50. \\ \hline
Test Notification & Info & Script & Notification on which test is running \\ \hline
Read File Error & Info & Reading File & Error when reading the correct file. File not exists.\\ \hline
Data Conversion & Info & Reading File & Data File is being converted \\ \hline
Head Running & Info & Reading File & Head was successfully run \\ \hline
File Type Info & Info & Data Parsing & Displays the file version type \\ \hline
Plot Notification & Info & Plotting & Displays the type of plot that was created \\ \hline
Iteration Notification & Info & Metrics & Notifies the user iteration number and time \\ \hline
Run time and Memory & Info & Closing & Notifies the user what the run time and memory usage is \\ \hline
\end{tabular}
\end{table}

\subsection{Function Library}

It was a much neater way to port most of the code into functions and save it into a seperate script.
The implementation details of each of the functions will not be detailed in this section.
Instead a short description of each function will be given.\\

The following is the complete list of functions created.

\begin{description}
\item[runHead] \hfill \\ This function is used to trim the original dataset down to the sample size specified.
It uses the linux system command $head$ and saves the new file into the same directory. 
There is also a logging command when the command is successful.
This function is only called when the required file does not exist.
\item[createArguments] \hfill \\ Due to the large number of arguments required, this function creates all of the arguments, then returns the argument parser to the main script. 
\item[initLogger] \hfill \\ This function declares the logger based on a few command line arguments (verbose or quiet). 
It also adds both a command line and a file logger to the object.
\item [parseFileName]\hfill \\ parseFileName takes in 3 arguments: test number, directory, and the direction of delay (called column in this function). 
Using the summary test sheet page stored in an .ODS file, this function will take the directory name based on the test number.
Some checks will be made to determine whether the directory or test number is valid. 
A list is then returned consisting of the fileName, the test number, the delay index and the test sheet object. 
\item [readFile] \hfill \\ This function attempts to read the file that the previous function had derived based on the input paramenters.
If the file is not read successfully an error is thrown. 
The runHead function is then called to create the correct file, and the file is read again.
If a second error is thrown then the script quits with a non-zero return value.
\item [readFileDirect] \hfill \\ Compared with the previous function, this once takes in a raw filename and will exit the script if it fails on the first time round.
This function is only used when the user knows which file they want to parse.
\item [purgeData] \hfill \\ Once the data has been written, it will be purged. 
Depending on the data type (the old or new format), it needs to be handled in two different ways.
Therefore an if statement is used to determine which file format it is in, then handled accordingly. The two arrays of delays and time are returned along with the correct number of samples. 
\item [plotArray] \hfill \\ This function plots the metrics as a line graph. 
It saves them in a postscript format, using the test number, metric type and the sample size in the file name.
This function can plot $n$ number of plots with a different coloured line.
\item [generateResultsArray] \hfill \\ This creates a much larger array called $result$ which consists of all of the results. 
This is then later used to output the results to particular formats.
\item [outputTable] \hfill \\ This function will convert the results table generated by the previous function to a CSV file or a table in \LaTeX if requested using the command line arguments. 
The CSV file is created using a built in function called write.csv, whereas the \LaTeX table is generated using a custom made function.
\item [calculateMetrics] \hfill \\ The different packet metrics are calculated in this function.
Note that this is the final packet metric function and thus only contains the most recent changes. 
The original design had two functions implemented in R, as detailed in a previous section.
Any optimisation techniques are discussed in a latter stage of this report.
\item [convertData] \hfill \\ Using the parseData awk script described previously, this R function calls this script to parse the original data file into the new format.
It firsts checks if the correct directory exists, and creates it if it doesnt using $mkdir -p$. 
It will then return the path that the file was created in. 
\item [interactiveMenu] \hfill \\ Finally the last function creates an interactive menu in case the user does not know all of the input argument flags required to run the script. 
\end{description}


\subsection{Testing}
\subsubsection{Overview}
Throughout the development of these scripts there was testing involved, both formalised unit testing and general development testing of each function. 
Testing is not just used to determine where bugs lie in the code, as it also helps to identify possible areas for optimisation, determining that all edge cases are covered, and that all input arguments are handled correctly. \\

General code development will not be discussed in this section because that is part of any programming project.
Instead some information on the unit testing performed will be highlighted as well as the major problems that the script faced during its development.

\subsubsection{Unit Testing}

Unit testing is a formalised method in making sure that when changes are made to a function or a piece of code, that all functions are still working to specification. 
These are usually combined with building tools, but in the case for R there is a unit testing library available that can be used.\\

Formalised testing takes a long time to put together to catch all errors when developing a program, thus not as much testing was performed on this script as what should've been done.
The following table (Table \ref{table:unittesting} outlines the list of tests required for each of the functions, with Appendix \ref{UnitTests} showing the unit tests created.

\begin{table}[H]
\centering
\caption{Unit Tests Identified}
\begin{tabular}{|l|l|l|l|l|} \hline
\cellcolor{Black}\textcolor{White}{\textbf{Test Name}} &
\cellcolor{Black}\textcolor{White}{\textbf{Function}} &
\cellcolor{Black}\textcolor{White}{\textbf{Type of Test}} &
\cellcolor{Black}\textcolor{White}{\textbf{Pass Value}} &
\cellcolor{Black}\textcolor{White}{\textbf{Fail Value}} \\ \hline
Sample Size Bounds & runHead & Integer Test & 0 < Value < Max & < 0 or > Max \\ \hline
Sample Size Type & runHead & Type Test & Integer & Not Integer \\ \hline
Arg Parser & createArguments & Library Exist & Library exists & Library does not exist \\ \hline
Init Logger Logical & initLogger & Input & Set to correct mode & Throw error \\ \hline
Init Logger Dir. not exist & initLogger & Directory & Successfully created & Throw error \\ \hline

\end{tabular}
\end{table}

The tests above are some of the tests performed on the functions detailed above. 
\subsubsection{Runtime and Memory Requirements}

As well as testing to ensure that the script meets the required functionality, it also needs to meet a requirements in that it needs to run in a reasonable amount of time within a suitable memory bound. 
Defining both of these was difficult as it was hard to predict ahead of time what a reasonable amount of time would be for both of them.
It was decided that time bound for a set of metric data would be \textbf{5 minutes} and the memory bounds work should be \textbf{1GB}.
Note that this time refers to the entire script, but some tests may be performed on a per iteration basis.\\

The script was run using the example data gathered before the project began.
It was noted that there would not be a significant time difference between the data sets provided that the length of it was kept the same.\\

There are profiling tools available to R, including Rprof \cite{Rprof}, but the simplest method to profile the speed of the script is to 
record the time when the script is loaded, then record the new time once it has finished.
The difference in these two times will be the execution time.\\

Similarly for memory requirements, Rprof is able to profile this, but instead a more simpler method was used which involved calling
$object.size(x=lapply(ls(), get)))$ at the end of the script. 
An example output can be shown below, Figure \ref{fig:exampleMem}. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{Figures/Screenshots/examplemem.eps}
\caption{Example Output for Runtime and Memory Requirements}
\label{fig:exampleMem}
\end{figure}

The following table (Table \ref{table:runtimeMem}) outlines both the runtime and memory requirements for a number of different sample sizes.
All of these tests were performed on the same computer. 
\begin{table}[H]
\centering
\caption{Runtime and Memory Requirements for ExampleData}
\begin{tabular}{|l|l|l|l|} \hline
\cellcolor{Black}\textcolor{White}{\textbf{Sample Size}} & \cellcolor{Black}\textcolor{White}{\textbf{Per Iteration (ms)}} &\cellcolor{Black}\textcolor{White}{\textbf{Total Time (ms)}} & \cellcolor{Black}\textcolor{White}{\textbf{Memory (KB)}} \\ \hline
50 & & & 380.064 \\ \hline
100 & & & 392.424\\ \hline
500 & && 491.176\\ \hline
1000 & & & 614.536 \\ \hline
5000 & & & 1601.240\\ \hline
10000 & & & 2834.600 \\ \hline
\end{tabular}
\label{table:runtimeMem}
\end{table}

\begin{comment}
The data has been plotted in Figure \ref{fig:runmemorig} below.

\begin{figure}[H]
\centering
\begin{subfigure}{\textwidth}
	\centering
%	\includegraphics[scale=0.5]{Figures/RunTime.eps}
	\caption{Runtime Requirements}
	\label{fig:runTimeorig}
\end{subfigure}%
\begin{subfigure}{\textwidth}
	\centering
%	\includegraphics[scale=0.5]{Figures/MemoryReq.eps}
	\caption{Memory Requirements}
	\label{fig:memorig}
\end{subfigure}
\caption{Runtime and Memory Requirements for Example Data}
\label{fig:runmemorig}
\end{figure}
\end{comment}
%Discussion on the above
\subsection{Optimisation}

Based on the above results, it is clear that there needs to be some speed improvement to the script in order for it to be useful. 
Because the script will not be run on an embedded system, this problem is not bound by memory, therefore only speed optimisations will be made.\\

It was important to determine which parts of the script were running slowly. 
It was fairly clear where the slow part of the script lies from the data gathered in the previous
section.\\

The metric calculation (per iteration) took much longer than previously anticipated.
The calculation involves a single for loop of different length, but the length varies on the sample size.\\

The following were a few ideas to speed up this process.

\begin{description}
\item[Use Existing Data] If possible, only incremental calculations can be made on successive iterations, thus cutting out the number of loops required. 
When looking at this particular application, because the for loop bounds depend  on the current iteration number and the total sample size, it would not be 
possible. 
In addition to this the final quotient consists of the sample size and the current iteration, therefore the value will be incorrect if previous sets of 
data were taken.
This means that it would not be possible to use this method to speed up the operation.
\item[Vectorise] The  second possible method would be to vectorise the solution. 
Similar with Matlab, R can be slow with iterative methods and excels at vector operations.
The function would speed up significantly if a vectorised method was possible.
But due to the use of the built in functions $mean$, $min$ and $bandMean$, there is not an obvious way in going about this.
Therefore this method would not be suitable. 
\item[Port to a lower level language] The final method involves porting the for loop into a more lower level language, such as C or Fortran.
This would enable the inner part of the for loop to be executed much quicker which would decrease the time of execution.
\end{description}

Based on the above, C was chosen to implement the inner loops for both TDEV and MATIEMAFEAllMethod R files. 
The code was directly ported into C from R, but some extra work was required due to C not having the ability to slice arrays.

The amended code in C can be found in Appendix \ref{app:TDEVAllC} for the TDEV method in C and \ref{app:MATIEAllC} for the MATIE/MAFE method. \\

Some care had to be taken when converting the code from C to R. 
Due to the difference between how C and R handle array indices (C is zero indexed and R is one indexed), 
the for loops had to be changed by 1. 
Unfortunately there is no direct way to compare the results due to the likelyhood of floating point differences, 
so the C code will be taken for granted as being correct.
A table below of the result differences between the C code and the R code have been provided.

% If space permitting add in sections about how the code was created

The speed improvement from making these changes was more than three orders of magnitude. 
The table below shows the speed improvements that porting the code to C has made.

\begin{table}[H]
\caption{Speed Improvements from moving from R to C}
\begin{tabular}{|l|l|l|l|l|l|} \hline
\cellcolor{Black}\textcolor{White}{\textbf{Sample Size}} & \cellcolor{Black}\textcolor{White}{\textbf{TDEV R per iteration}} &
\cellcolor{Black}\textcolor{White}{\textbf{TDEV C per iteration}} & \cellcolor{Black}\textcolor{White}{\textbf{TDEV R full script}} &
\cellcolor{Black}\textcolor{White}{\textbf{TDEV C full script}} \\ \hline
50 & & 4 & & 544 \\ \hline
100 & & 4 & & 644 \\ \hline
500 & & 4 & & 1640\\ \hline
1000 & & 4 & & 4316 \\ \hline
5000 & & 60 & & 199660 \\ \hline
10000 & & 150 & & 706584 \\ \hline
\end{tabular}
\end{table}

\section{Analysis Methods}

\subsection{Overview}

This section details the analysis methods used on the data gathered. 
This will include the different plotting types used as well as any other relevant statistics.
There are three ways that the data could be displayed or handled to be able to draw conclusions from them.
These have been identified to be:

\begin{description}
\item[Tables] Tables would be the first method to display the data as the raw data can be added to the table.
The problem is that it is difficult to infer trends from a large data set, and thus would not be a suitable method for this application.
Note however that it may be a good method to take a snapshot of the data and be able to determine some characteristics of the data.
\item[Statistics] The second way to process the data is to use some basic statistics in a tabulated form. 
This allows it to be possible to quite quickly compare sets of data between each other, but it makes it difficult to be able to look within a set of data.
Each of the statistic types will be computed using inbuilt functions where possible. 
\item[Plotting] The final method would be to plot the results.
Due to there being a large number of plot types, this would be a suitable method to choose.
The data needs to be displayed in such a way that trends can be spotted quite easily. 
Therefore the following plot types will be used: scatter plots, histograms, heat maps and line graphs. 
Each of these will be used for a different set of data, and will be discussed below.
\end{description}

\subsection{Plot Types}

In order to best display and process the data gathered, several plots need to be created.
It is important as to what plot types are used as it can affect the conclusions drawn from them.
The plots detailed below were the ones chosen for this project.

\subsubsection{Scatter Plots}
Scatter plots will be the first type of plot used, mainly on the raw delay data. 
Provided there are enough data points, it is a useful method to be able to see general trends in delay data and to see if there are any abnormalities.
The plot below (Figure \ref{scatterExample}) shows two different examples of a scatterplot. 
Figure \ref{scatterExample:R} is one created using an R script, and the second is from the Syncwatch Lab program, discussed briefly in an earlier section.

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[scale=0.25,angle=270]{Figures/ScatterExampleR.eps}
	\caption{Scatter Plot Example in R}
	\label{scatterExample:R}
\end{subfigure}%
\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[scale=0.5]{Figures/ScatterExampleSync.eps}
	\caption{Scatter Plot Example in Syncwatch Lab}
	\label{scatterExample:Sync}
\end{subfigure}
\label{scatterExample}
\caption{Scatter Plot Examples}
\end{figure}

Both of these plots are very similar, with the R plot being more flexible in the fact that you can plot the whole data set instead of part of it.
The Syncwatch scatter plot will instead be used to show some anomalies in the results.\\

\subsubsection{Histograms}

The second plot type is histograms of the raw delay values.
This is another method of displaying the same data as before, but it is more related to the distribution of delays across the entire data set.
The figure below (Figure \ref{histogramExample} shows the two examples of histogram that will be used.
\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.5\textwidth}
	\centering
	\includegraphics[scale=0.25, angle = 270]{Figures/HistogramExampleR.eps}
	\caption{Histogram Plot Example in R}
	\label{histogramExample:R}
\end{subfigure}%
\begin{subfigure}[b]{0.5\textwidth}
	\centering
    \includegraphics[scale=0.5]{Figures/HistogramExampleSync.eps}
	\caption{Histogram Plot Example in Syncwatch Lab}
	\label{histogramExample:Sync}
\end{subfigure}
\label{histogramExample}
\caption{Histogram Plot Examples}
\end{figure}

The two histogram plots will show similar results, so instead the second histogram plot will be used for the long term data collection.
\subsubsection{Heat Maps}

If slices of time are taken, then converted to histograms and flattened to a 1dimensional coloured bar, a heat map of these time slices can be produced.
These can be produced in any language, such as Matlab or R.
An R implementation has been produced, and an example can be found below in Figure \ref{heatmapExample}. 

\begin{figure}[H]
\centering
%\includegraphics[scale=0.5]{Figures/HeatMapExample.eps}
\caption{Heat Map Example in Matlab/R}
\label{heatmapExample}
\end{figure}

This is a very pictorial way in showing changes in delay across a set of data.

\subsubsection{Line Graphs}

The final method of plotting the data will plot the metric data for both TDEV and MinTDEV.
As it is difficult to determine how this data should be plotted, a set of simple line graphs will be produced initially.
If a further plot type is required this will be highlighted in the results section. 

Two plot examples for a line graph are shown below, in Figure \ref{lineExample}.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.3,angle=270]{Figures/LineExampleR.eps}
	\caption{Line Graph Example in R}
	\label{histogramExample:R}
\end{figure}


\subsection{Plotting Implementation}

Taking these plots above, these plots can be implemented in R. 
The correct axis labels, legends (if appropriate), and line colours are also automatically generated.
The implementations of the plotting functions will not be explained in much detail, but they can be found in Appendix \ref{app:plot}, \ref{app:Hist} and \ref{app:cHist}. 

\section{Results}

This section will detail the results gathered from the above metrics as well as the other testing that was performed.
The summary table of all of the tests performed can be found in Appendix \ref{app:testsummary}. 
The following elements of PTP will be investigated using these results: Long Term Grandmaster Drift, Delay Distribution, Delay anomalies, Metric Results, Master to Slave vs Slave to Master amd Comparing times of Day / locations. 

\subsection{Long Term Grandmaster Drift}

The first set of results gathered was measuring the long term drift of the Chronos TimePort Grandmaster clock with respect to a Rubidium clock available in the lab. 
The clock used to compare it is a Rubidium oscillator.
The full specification sheet \cite{Rubidium} has been summarised in a tabular form in Appendix \ref{rubidium}.

The Rubidium clock used is a  Rubidium Frequency Standard FS725 made by \ac{SRS}.
It integrates a rubidium oscillator (model PRS10) with an AC power supply and distribution amplifiers.
It is a very stable oscillator with anticipated aging of less than 5x10-9 over a period of 20 years.
A photo of the Rubidium clock used can be seen below, Figure \ref{fig:rubidium}. 
The datasheet is referenced here on the \ac{SRS} website \cite{rubidium}. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/rubidium.eps}
\label{fig:rubidium}
:\caption{Rubidium Clock}
\end{figure}

The grandmaster clock (the Chronos TimePort) was compared with the Rubidium clock mentioned above, and this difference was plotted using the Alan Deviation.

%Explanation on TimeLab
%Explanation on the Counter
%Explanation on results

%---- Will look at the above on Monday -----

\subsection{Delay Distribution}

The next set of results is to compare delay distribution of the sets and to se if there are any interesting anomalies with the results.
See below the first set of data: the example set.
The time that these results were taken was unknown, but this will be used as a base line to compare the other results to. \\

\begin{figure}[H]
\centering
\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test0/DelayPlot.eps}
\caption{Example Data Set Delay Plot}
\label{Test0Delay}
\end{figure}

The first thing to note is that this has been taken at the start of the data set, and thus that is why there is a large delay that slowly tails off. 
After around 1800 samples (which is about a minute), the delays have stabilised. 
The important part of the results is this stabilised region and its overall spread. 
This same distribution can be seen throughout the data sets collected, with a sample of them shown in the multi figure below.\\

%There was a set of results (from Test 1 to Test \#) that were using the TimePort when it was in freewheeling mode.

%Look through all results. find some interesting stuff.

\begin{figure}[H]
\centering
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3, angle=270]{Figures/FinalResults/Test2/DelayPlot.eps}
	\label{delay:test2}
	\caption{Delay Plot - Test 2}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test6/DelayPlot.eps}
	\label{delay:test6}
	\caption{Delay Plot - Test 6}
\end{subfigure}

\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test7/DelayPlot.eps}
	\label{delay:test7}
	\caption{Delay Plot - Test 7}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test9/DelayPlot.eps}
	\label{delay:test9}
	\caption{Delay Plot - Test 9}
\end{subfigure}
\caption{Example of Delay Plots}
\end{figure}

Notice that there are some differences between these four examples.
Test 6 was the first Beaglebone test performed and it seems to show very similar results to the example data mentioned previously.
The reason for the high values of delays in some of these tests were due to the freewheeling mode that the \ac{GM} clock was under, and thus only the distribution can be looked into in any detail.\\

One interesting point to note however is with Test 7. 
The delay spread look initially a wide spread, but this is because as the scale has automatically changed, the total delay spread is actually much less in this case.

\subsubsection{Delays During the Test}
The delay plots above have been taken from the first 10000 samples of the test. 
The next set of plots will show the same tests covered above but further on in the data set. 
The data sets have been calculated 10000 samples in from the end of the data set.  \\

Same as before, the first figure below is with the example data set. 


\begin{figure}[H]
\centering
\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test0/DelayPlotMid.eps}
\caption{Example Data Set Mid Delay Plot}
\label{Test0DelayMid}
\end{figure}

Note that the delay has reached its steady state point and the delay variations around the median are due to errors. 
The delay is mainly around 10 \mu s, but has peaks of up to 200\mu s. 
The noise distribution seems to be fairly uniform with no clear discrete noise sources causing these delays.
The same tests as in the previous section have been added below, in Figure \ref{delaymidPlots} 
\begin{figure}[H]
\centering
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3, angle=270]{Figures/FinalResults/Test2/DelayPlotMid.eps}
	\label{delay:test2mid}
	\caption{Delay Plot Mid Set - Test 2}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test6/DelayPlotMid.eps}
	\label{delay:test6mid}
	\caption{Delay Plot Mid Set  - Test 6}
\end{subfigure}

\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test7/DelayPlotMid.eps}
	\label{delay:test7mid}
	\caption{Delay Plot Mid Set - Test 7}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test9/DelayPlotMid.eps}
	\label{delay:test9mid}
	\caption{Delay Plot Mid Set - Test 9}
\end{subfigure}
\caption{Example of Delay Mid Plots}
\label{delaymidPlots}
\end{figure}

Discussion on the above
\subsubsection{Irregular Delay Magnitudes}

A second observation was made with the Syncwatch Plots. 
See Figure \ref{Syncwatch:normal}, which shows the delay profile in steady state.
As expected the delay is relatively static with some noise over the top.
This is in contrast to Figure \ref{Syncwatch:strange}, where it seems like there are discrete delay variations surrounding the mean value.\\

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[scale=0.5]{Figures/FinalResults/SyncwatchNormal.eps}
    \caption{Syncwatch Plot Normal}
    \label{Syncwatch:normal}
\end{subfigure}%
\begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[scale=0.5]{Figures/FinalResults/SyncwatchStrange.eps}
    \caption{Syncwatch Plot Abnormal}
    \label{Syncwatch:strange}
\end{subfigure}%
\end{figure}
It can be seen in Figure \ref{Syncwatch:strange} that there are around three discrete delay values with a couple of other noise peaks. 
This was very interesting when you compare it to the data discussed in the previous section where there was a clear spread of delay values without seeing any discreteness.

Throughout the data collection phase of the project several occurences of a very high delay peak was recorded.
A screenshot (Figure \ref{packetdata}) of some general test statistics is shown below for the main Syncwatch test.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/packetData.eps}
\caption{General Packet Data for the Syncwatch Test}
\label{packetdata}
\end{figure}

The figure above shows that the maximum packet delay value was over 25ms. 
This is clearly an extremely high packet data considering the test was only set up going through 7 switches.
This packet delay variation is therefore very interesting to note when PTP is run on a typical Ethernet network. \\

Referring back to Figure \ref{Syncwatch:strange}, it was not easy to determine what cases this occurred. 
The day which this was most noticeable coincided with a few network engineers working on a network cabinet downstairs on Level 2, but it was not conclusive whether these two events were related or just a coincidence.
In addition to this it seemed as though if a slave clock running on a lab desktop machine was run in tandem with the Syncwatch test, this delay quantisation effect was reduced to almost nothing, and the delay looked like the normal figure in Figure \ref{Syncwatch:normal}. 
Some reasons as to why this happens will be explored at the end of this report.

\subsubsection{Histogram Distribution}

Histograms have been used to be able to easily work out the histogram delay distribution.
For example, the plot below is from the example data set.

%----- Need more bins  ------

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/FinalResults/Test0/HistogramTest0Sample9996.eps}
\caption{Histogram of Example Set}
\label{Hist:example}
\end{figure}

%Explain the distribution.

The delay distribution of some of the tests is shown below, Figure \ref{fig:histPlots}. 


\begin{comment}
\begin{figure}[H]
\centering
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3, angle=270]{Figures/FinalResults/Test2/HistPlot.eps}
	\label{hist:test2}
	\caption{Histogram Plot - Test 2}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test6/HistPlot.eps}
	\label{hist:test6}
	\caption{Histogram Plot - Test 6}
\end{subfigure}

\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test7/HistPlot.eps}
	\label{hist:test7}
	\caption{Histogram Plot - Test 7}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test9/HistPlot.eps}
	\label{hist:test9}
	\caption{Histogram Plot - Test 9}
\end{subfigure}
\label{Example of Delay Plots}
\end{figure}
\end{comment}

%Explanation of the delay distribution.
%Verify that it matches what is found in the other plots


\subsection{Master to Slave vs Slave to Master}

The next test would be to compare the one way delay direction against each other for similar tests.
Test 0 (The example data set) will first be used to see what the delay differences are if any.
The plot below (Figure \ref{delay:bothDir})is the Master to Slave and Slave to Master delay plotted on the same graph.

\begin{figure}[H]
\centering
%\includegraphics[scale=0.5]{Figures/FinalResults/Test0Both.eps}
\label{delay:bothDir}
\caption{Bi-directional delay for the example set of Data}
\end{figure}

%Pick only a few examples of these plots and explain them

\begin{comment}
\begin{figure}[H]
\centering
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3, angle=270]{Figures/FinalResults/Test2/HistPlot.eps}
	\label{hist:test2}
	\caption{Histogram Plot - Test 2}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test6/HistPlot.eps}
	\label{hist:test6}
	\caption{Histogram Plot - Test 6}
\end{subfigure}

\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test7/HistPlot.eps}
	\label{hist:test7}
	\caption{Histogram Plot - Test 7}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
	\includegraphics[scale = 0.3,angle=270]{Figures/FinalResults/Test9/HistPlot.eps}
	\label{hist:test9}
	\caption{Histogram Plot - Test 9}
\end{subfigure}
\label{Example of Delay Plots}
\end{figure}
\end{comment}
Comment on the results above
%Calculate some other plot types and carry on with the results

\subsection{Comparing times of day}

This next text aims to try and see how time of day affects the testing. 
The hypothesis for this part of the test guesses that as the network is busier there will be a bigger spread of delays. 
The tests used for this will have the biggest difference associated with them. 

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[scale=0.5]{Figures/FinalResults/Master2Slave.eps}
    \caption{Master 2 Slave}
    \label{Test0Normal}
\end{subfigure}%
\begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[scale=0.5]{Figures/FinalResults/Test0/Direction/Slave2Master.eps}
    \caption{Slave to Master}
    \label{Slave2Master}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[scale=0.5]{Figures/FinalResults/Test0/Direction/Difference.eps}
\label{timeOfDay}
\caption{Example Data Comparison between Directions}
\end{subfigure}
\end{figure}

%Explanation of the delay differences being the same. 
% Either have a set of plots to show the same thing, or maybe different ones if it is different


\subsection{Metric Results}

The next set of results calculated were using the packet metric scripts created in a previous section of this report.
Same as before, the scripts were run using the Example test data first and some initial conclusions were drawn.
The scripts then calculated both metrics and plotted them for all of the data sets collected. 
The example data set metric plots can be seen below : Figures \ref{test0:TDEV} and \ref{test0:MATIE} for TDEV and minTDEV respectively. 

\begin{figure}[H]
\centering
\begin{subfigure}{\textwidth}
    \centering
    \includegraphics[scale=0.5]{Figures/FinalResults/Test0/TDEVPlot.eps}
    \caption{Test 0 : TDEV Plot}
    \label{test0:TDEV}
\end{subfigure}%

\begin{subfigure}{\textwidth}
    \centering
    \includegraphics[scale=0.5]{Figures/FinalResults/Test0/MATIEMAFEPlot.eps}
    \caption{Test 0: MATIE MAFE Plot}
    \label{test0:MATIE}
\end{subfigure}
\caption{Example Data Metric Plots}
\label{test0:metrics}
\end{figure}
%Explanation of these metrics briefly.

%Read report regarding what these mean.

\subsubsection{Test 1: Normal Conditions}

The first test completed during the course of this project was Test 1. 
Other repetitions of this test was also performed.
The metric plots can be seen below: Figures \ref{test1:TDEV} and \ref{test1:MATIE}. 

\begin{figure}[H]
\centering
\begin{subfigure}{\textwidth}
    \centering
    \includegraphics[scale=0.5]{Figures/FinalResults/Test1/TDEVPlot.eps}
    \caption{Test 1 : TDEV Plot}
    \label{test1:TDEV}
\end{subfigure}%

\begin{subfigure}{\textwidth}
    \centering
    \includegraphics[scale=0.5]{Figures/FinalResults/Test1/MATIEMAFEPlot.eps}
    \caption{Test 1: MATIE MAFE Plot}
    \label{test:MATIE}
\end{subfigure}
\caption{Test 1 Metric Plots}
\label{test0:metrics}
\end{figure}



\section{Discussion}
\section{Challenges}
\section{Milestones}
\section{Conclusion}

In conclusion the \ac{PTP} protocol was investigated successfully in a number of different ways.
\ac{PTP} data was collected in a number of different locations throughout the university on several different clock configurations.
This data was then analysed: both through looking at the raw delays and from the use of packet metric scripts.
It was found that...
Secure PTP was also looked into to see how PTP can be made more secure. 

\section{Further Work}

Due to the openness of the project, there is a number of additional tasks that could be completed to continue the investigation.
These have been identified below.

\begin{description}
\item[Different Network Topologies] Due to the equipment available, it was difficult to test \ac{PTP} on different network types.
Therefore it would be beneficial to perform the same tests as before but with different topologies.
This would enable to better test the protocol in more common scenarios with the use of boundary and transparent clocks. 

\item[More Packet Metrics] Once a better understanding of the packet metrics is gathered, more packet metrics can be implemented where necessary. 

\item[Verify Packet Metric Scripts against existing programs] Because there were no existing packet metric programs available to be used during this project, the scripts were not tested for validity. 
The results looked correct hence why these were used for investigating \ac{PTP} performance. 
Chronos has a packet metric software suite as an add on to the Syncwatch software  
\item[Secure PTP] There has been some work done when describing Secure PTP (Section \ref{securePTP}), but if there was more time more work on this would have been investigated. 
Some work into making a PTPd secure implementation would be looked at.
In tandem with this a PTP network could be set up and attempts would be made to try and damage the network through its various attack vectors to demonstrate PTPs weaknesses. 
\end{description}

\section{Other Work}

\subsection{Securing PTP against attacks}
PTP Security Tutorial
http://www.ispcs.org/security/downloads/PTPSecurityTutorial.pdf \\

PTP is inherently an unsecure system with no standard methods in either encrypting communications between the master and the slave devices or any method of verifying that a particular grandmaster is legitamate.
	Therefore the slave clocks rely on trusting the grandmaster is an accurate time reference and blindly syncronising with the masters.
The issue arises if a master or grandmaster was compromised and clock shift delays were spoofed.
This would cause all of the slave clocks on the network to drift away from the actual time reference.
The impact on critical systems mentioned in this report would be huge: timestamps for telecommunications data would be invalid or power transmission relays would trigger in the wrong order.
Therefore this section of the report will highlight some of the attack vectors that could affect PTP and methods in which to help mitigate this.

\subsubsection{Issues with NTP}

* find documentation on the NTP DDOS type attack style *
* comment whether it's possible with PTP*
\subsubsection{Possible Attack Vectors}

There a number of different methods that are possible with the existing \ac{PTP} standard.
These are:

\begin{description}
\item[Control Plane Attack] \hfill \\ This attack is an attack specifically on the \acf{BMC} algorithm which is highlighted in Section \ref{ref:BMC}. 
It works by having a compromised host (pictured below in red, Figure \ref{fig:ControlPlane}) announcing to the network that it has set the highest priority flag to 1. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/PTPSecurity/ControlPlane.eps}
\caption{Control Plane Attack Vector (taken from ref)}
\label{fig:ControlPlane}
\end{figure}

This would set it to become the Grandmaster clock on the network based on the \ac{BMC} algorithm. 
The existing \ac{GM} clock is now passive and the new grandmaster can now steer all of the slave clocks on the network by reporting false timestamps. 
Provided that the compromised host keeps their priority level at the highest, the only method of fixing this type of attack would be for another master clock to also set their priority to the highest.
The \ac{BMC} algorithm will then drop to the next level, which is Clock Type (need to check). \\

A more sophisticated version of this attack could be for the compromised clock to eventually mirror all of the parameters for the current grandmaster, such that it would be a random choice which clock would be chosen as the Grandmaster. 

\item[Sync Plane Attack] \hfill \\ This attack type involves the compromised clock to learn enough about the existing grandmaster to be able to spoof messages as if the compromised clock was the grandmaster.
It does this by learning the \ac{GM} identity, addresses, sync sequence number and interval. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/PTPSecurity/SyncPlane.eps}
\caption{Sync Plane Attack Vector (taken from ref)}
\label{fig:SyncPlane}
\end{figure}

From the perspective of one of the slaves, this compromised clock is exactly the same as the current grandmaster.
The compromised clock can then send sync messages, thus hijacking the slave clocks on the network. 
This is a form of a masquerade attack. \\

Due to the nature of this attack, it would be difficult to attempt to mitigate the risk of this type of attack occurring on a PTP network because the real grandmaster and the hacked host look identical. \\

One way that network administrators could attempt to mitigate this however is to restrict any two devices with the same parameters on the network from communicating.
This would involve some sort of authentication process that cross checks all possible masters. 
	

\item[Management Plane Attack] \hfill \\ The final attack type involves using a management command to gain grandmaster access on the network. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/PTPSecurity/ManagementPlane.eps}
\caption{Management Plane Attack Vector (taken from ref)}
\label{fig:ManagementPlane}
\end{figure}

It involves gaining access to the clocks to disrupt network operation by sending an initialise command.

%*need some more info*

\item[Delay Attacks] \hfill \\ The final attack type is a delay attack, which involves a compromised switch instead of a host. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Figures/PTPSecurity/DelayAttack.eps}
\caption{Delay Attack}
\label{fig:DelayAttack}
\end{figure}
\item[Confidentiality and Non-Repudiation] \hfill \\ Test. add in some info here

\end{description}

Figure \ref{fig:DelayAttack} demonstrates what would happen if this occured.
The hijacked switch (when acting like a boundary clock) would be able to report incorrect delay values which would then propagate these errors across the network.\\

The problem with mitigating this type of attack is, unlike the three previous attack types, is that it would be difficult to redirect routing of the PTP packets around the compromised switch.
One way of mitigating is that the delays could be sanity checked with a number of different routes, similar to how clocks in every stratum in NTP are sanity checked.

\subsubsection{Methods to mitigate the above attack vectors}

There are several general methods of securing a PTP network in general, with some other specific methods also mentioned in relation to the attacks mentioned above.
The general methods are:

\begin{itemize}
\item Physically Securing the Network
\item Use seperate sub-networks to limit the effect of multicast communication
\item Limit the grandmasters to a pre-defined list by implementing a whitelist
\item Limit the management address to a pre-defined list
\item Snoop source address to attempt to identify masquerade attacks
\end{itemize}

The above methods would be able to mitigate some of the attack types but they are either not always possible to implement, don't cover some of the more serious threats to the network, or the goal of minimising central administration would not be reached.
For example, physically securing the network may not always be fool-proof or may not be possible in certain circumstances.
The issue with limiting either the grandmasters or the management addresses is the extra overhead involved in administrating the network, which goes against the original goals of PTP to have distributed control. \\

IEE1588-2008 standard includes a section on secure PTP which aims to address these concerns. 
This is in Appendix J of the standard. 
Some of the solutions mentioned in the standard will be discussed here, along with some comments and suggestions to move forward, and areas that could be later worked on to better improve the security of PTP. 

\subsubsection{Security Protocol Recommendation}

Annex K of the IEEE1588-2008 specification outlines a recommendation to how secure PTP could be implemented.
It explicitly states that this section is not a requirement to meet the standard, just a possible way of implementing it.
The extension to the standard includes group source authentication, message integrity and replay attack protection, which would help to mitigate some of the attack vectors mentioned previously. \\

The security protocol includes two main elements: an integrity protection mechanism and a challenge-response mechanism. 
Symmetric message authentication code functions are used which provides the advantages of replay proection, group source authentication and message integrity. 
The standard recommends two main authentication standards (HMAC-SHA1-96 \ref{HMAC-SHA1-96} and HMAC-SHA256-128 \ref{HMAC-SHA256-128}), but there is a possibility for the standard to support more than these.\\

Users on the PTP network will share symmetric authentication keys, which can either be shared across an entire domain or in subsections of it. 
There are two ways of key distribution: either manual or an automatic key management protocol. \\

\paragraph{Security Associations}

The method of communication between users on the PTP network is through \acp{SA}. 
The contain the following fields:

\begin{itemize}
\item Source (Source port and Protocol Address)
\item Destination (Destination Address and Protocol Address)
\item key (either SHA256-128 or SHA1-96)
\item a random lifeTimeID
\item a reply counter
\end{itemize}

The \ac{SA} is a unidirectional transaction, therefore each node on the network needs to maintain a list of both incoming \acp{SA} as well as outgoing. 
They can be shared by a single sender and multiple receivers, but each receiver holds its own copy of the \ac{SA}. 
This will work provided that each of the receiver copies holds a different value of the reply protection counter at the same time. 
All of them must be smaller than the counter stored in the sender's copy.
The \ac{SA} is generated by the sender, and can be sent to all of the receivers, or a seperate one to each of them.\\

%Replay protection mechanism

%\paragraph{Requirements}




%\section{Acknowledgements}
\bibliography{Bibliography}
\begin{appendices}
\section{Clock Accuracies}
\label{clockaccuracies}
\begin{table}[H]
\caption{Clock Accuracies}
\begin{tabular}{|c|c|c|c|c|} \hline
\multirow{2}{*}{\cellcolor{Black}} & \multicolumn{1}{|c|}{\cellcolor{Black}\textcolor{White}{\textbf{Quartz Oscillators}}} & \multicolumn{3}{|c|}{\cellcolor{Black}\textcolor{White}{Atomic Oscillators}} \\ \hline
& \textbf{OCXO} & \textbf{Rubidium} & \textbf{RbXO} & \textbf{Ceasium} \\ \hline
\textbf{Accuracy} (per year) &  1x10-8 & 5x10-10 & 7x10-10 & 	2x10-11 \\ \hline
\textbf{Ageing} (per year) & 5x10-9 & 2x10-10 & 2x10-10 & 0 \\ \hline
\textbf{Temperature Stability} & 1x10-9 (-55 to 85) & 3x10-10 (-55 to +68) & 5x10-10 (-55 + 85) & 2x10-11 (-28 to +65) \\ \hline
\textbf{Stability}, S\textsubscript{y} t = 1s & 1x10-12 & 3x10-12 & 5x10-12 & 5x10-11 \\ \hline
\textbf{Size} (cm\textsuperscript{2}) & 20-200 & 800 & 1200 & 6000 \\ \hline
\textbf{Warmup Time} (minutes) & 4 (to 1x10-8) & 3 (to 5x10-10)  & 3 (to 5x10-10) & 20 (to 2x10-11) \\ \hline
\textbf{Power (W)} (at lowest temp.) & 0.06 & 20 & 0.65 & 30 \\ \hline
\textbf{Price \$} & 2000 & 8000 & 10000 & 40000 \\ \hline
\end{tabular}
\end{table}
\section{Gantt Chart and Table}
\label{app:ganttchart}
\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{Figures/GanttChart.eps}
\caption{Gantt Chart}
\end{figure}
\begin{table}[H]
\begin{tabular}{|c|c|c|c|c|c|} \hline 
\cellcolor{Black} & \cellcolor{Black}\textcolor{White}{\textbf{Task Name}} & \cellcolor{Black}\textcolor{White}{\textbf{Duration (days)}} & \cellcolor{Black}\textcolor{White}{\textbf{Start}} & \cellcolor{Black}\textcolor{White}{\textbf{Finish}} & \cellcolor{Black}\textcolor{White}{\textbf{Predecessors}} \\ \hline
A & \textbf{Deliverables} & 72 & Mon 03/02/14 & Tues 13/05/14 & \\ \hline
1 & Log Book & 65 & Mon 03/02/14 & Fri 02/05/14 & \\ \hline
2 & Interim Report & 9 & Fri 07/02/14 & Wed 19/02/14 & B, 1 \\ \hline
3 & Final Year Report & 17 & Mon 14/04/14 & Tues 06/05/14 & B,C,D,1,2 \\ \hline
4 & Poster & 5 & Wed 07/05/14 & Tues 13/05/14 & 1,3 \\  \hline
\cellcolor{Black}\textcolor{White}{\textbf{B}} & \cellcolor{Black}\textcolor{White}{\textbf{Preliminary Reading}} & \cellcolor{Black}\textcolor{White}{\textbf{7}} & \cellcolor{Black}\textcolor{White}{\textbf{Mon 03/02/14}} & \cellcolor{Black}\textcolor{White}{\textbf{Tues 11/02/14}} & \cellcolor{Black}\\ \hline
1 & Read up on PTP & 7 & Mon 03/02/14 & Tues 11/02/14 & \\ \hline
2 & Reading about Metrics & 7 & Mon 03/02/14 & Tues 11/02/14 & \\ \hline
\cellcolor{Black}\textcolor{White}{\textbf{C}} & \cellcolor{Black}\textcolor{White}{\textbf{Packet Metrics}} & \cellcolor{Black}\textcolor{White}{\textbf{35}} & \cellcolor{Black}\textcolor{White}{\textbf{Mon 10/02/14}} & \cellcolor{Black}\textcolor{White}{\textbf{Fri 28/03/14}} & \cellcolor{Black} \\ \hline
1 & Decide on Language & 1 & Mon 10/02/14 & Mon 10/02/14 & \\ \hline
2 & Decide on Metrics & 1 & Mon 10/02/14 & Mon 10/02/14 & \\ \hline
3 & Implement Metrics & 24 & Mon 11/02/14 & 14/03/14 & 1,2 \\ \hline
4 & Test all Metrics & 33 & Wed 12/02/14 & Fri 27/03/14 & 3 \\ \hline
5 & Run some tests on sample Data & 8 & Wed 12/02/14 & Fri 21/02/14 & 3 \\ \hline 
\cellcolor{Black}\textcolor{White}{\textbf{D}} & \cellcolor{Black}\textcolor{White}{\textbf{Data Collection}} & \cellcolor{Black}\textcolor{White}{\textbf{45}} & \cellcolor{Black}\textcolor{White}{\textbf{Mon 03/02/14}} & \cellcolor{Black}\textcolor{White}{\textbf{Tues 04/04/14}} & \cellcolor{Black} \\ \hline
1 & Set up Equipment & 5 & Mon 03/02/14 & Fri 07/02/14 & \\ \hline
2 & Run Tests w/ Chronos Equipment & 10 & Mon 24/02/14 & Fri 07/03/14 & 1\\ \hline
3 & Run Tests w/ Software & 5 & Mon 10/03/14 & Fri 14/03/14 & 1 \\ \hline
4 & Run Tests with w/ Mix & 5 & Mon 17/03/14 & Fri 21/03/14 & 1 \\ \hline
5 & Other Tests & 10 & Mon 24/03/14 & 04/04/14 & 1 \\ \hline
6 & Run scripts on Results & 30 & Mon 24/02/14 & Fri 04/04/14 &  2,3,4,5 \\ \hline
\cellcolor{Black}\textcolor{White}{\textbf{E}} & \cellcolor{Black}\textcolor{White}{\textbf{Other Work and Buffer}} & \cellcolor{Black}\textcolor{White}{\textbf{12}} & \cellcolor{Black}\textcolor{White}{\textbf{Mon 07/04/14}} & \cellcolor{Black}\textcolor{White}{\textbf{Fri 18/04/14}} & \cellcolor{Black} \\ \hline
\end{tabular}
\end{table}

\section{Chronos CTL4540 TimePort Specification}
\label{app:TimePortSpec}
\begin{table}
\begin{tabular}{l l } \\
\multirow{2}{\textbf{IPPS Holdover}} & 200 nanoseconds over 8 hours (\pm $10\,^{\circ}\mathrm{C}$ temp change)  \\ 
& 100 nanoseconds ove 4 hours (\pm $10\,^{\circ}\mathrm{C}$ temp change) \\ 
\textbf{\large{Inputs}} \\ 
+5V DC: & MiniB USB \\ 
GPS antenna: & SMA \\
Ethernet (PTP and SNTP/NTP): & RJ45 10/100 \\ 
Ethernet (management): & RJ45 10/100 \\
1PPS (phase 2): & BNC \\ \\
\textbf{\large{Outputs}} \\ 
1PPS: & BNC \\
Frequency 1: 2.048 MHz, 10 MHz & BNC G.703 \\
Frequency 2: 2.048 MHz, 10 MHz & BNC G.703 \\
IRIG-B: & BNC \\
RS232: & 9 way D-Type 9600 band \\
RS442: & 15 way D-Type 9600 band \\
Ethernet (PTP and SNTP/NTP) (Max 10 clients): & RJ45 10/100 \\
Ethernet (management): & RJ45 10/100 \\ \\
\textbf{\large{Environmental}} \\
Operating Temperature:  & $0\,^{\circ}\mathrm{C}$ to +$50\,^{\circ}\mathrm{C}$ \\
Maintain holderover tolderance down to: & $ -10\,^{\circ}\mathrm{C}$ for 15 minutes \\
Storage temperature:  & $-20\,^{\circ}\mathrm{C}$ to +$80\,^{\circ}\mathrm{C}$ \\ \\
\textbf{\large{Physical}} \\
Size: & 190 x 57 x 170mm (WxHxL) \\
Weight: & 1150g \\ \\
\end{tabular}
\end{table} 
\section{TimePort Documentation}
\label{app:TimePortDocumentation}
\includepdf[pages={1, 2}]{TimePortDocumentation.pdf}
\section{Syncwatch Documentation}
\label{app:SyncwatchDocumentation}
\includepdf[pages={1, 2}]{SyncwatchDocumentation.pdf}
\section{Test Sheet Example}
\label{app:testsheet}
\begin{table}[H]
\begin{tabular}{|l|l|p{3cm}|l|l|} \hline \\
\multicolumn{5}{|c|}{Test: Timeport\_to\_Software Test One} \\ \hline
 \textbf{Test Name:} & \multicolumn{2}{|l|}{TimePort\_To\_Software Test One} & & \\ \hline
 \textbf{Test ID:} & \multicolumn{2}{|l|}{001} & &\\ \hline
 \textbf{Test Date} & \multicolumn{2}{|l|}{2014-02-27} & & \\ \hline
 \textbf{File Name:} & \multicolumn{2}{|l|}{RawData.txt} & &\\ \hline
 \textbf{Directory:} & \multicolumn{2}{|l|}{./PTPData/TimePort\_To\_Software\_Test1} & &\\ \hline
 \textbf{Start Time:} & \multicolumn{2}{|l|}{1037} & &\\ \hline
 \textbf{End Time:} &\multicolumn{2}{|l|}{2200} & &\\ \hline
\textbf{Clock \#1 Type:} & Hardware & & \textbf{Clock \#2 Type:} & Software \\ \hline

\textbf{Clock \#1 Name:} & TimePort\_1 & & \textbf{Clock \#2 Name:} & PTPd\_Netbook \\ \hline
\textbf{Clock \#1 Model:} & TimePort & & \textbf{Clock \#2 Model:} & PTPd \\ \hline
\textbf{Clock \#1 Location:} & Watson's Office & & \textbf{Clock \#2 Location:} & 2E 2.13 \\ \hline 
& & & &\\ \hline
\textbf{Network Activity:} & Normal & & & \\ \hline
\textbf{Test Description:} & \multicolumn{4}{|l|}{An initial test to collect data to supplement the example data already received. } \\ \hline
\textbf{Comments} & \multicolumn{4}{|l|}{1342: Data seems to be collecting fine. 3hrs20mins: 45MB} \\ \hline
\end{tabular}
\end{table}
\section{Test Sheet Summary Sheet}
\label{app:testsummary}
\input{SummaryTestSheet.latex}
\section{Awk Script}
\label{app:awkscript}
\lstinputlisting[caption=Awk Script, language=awk]{../OtherScripts/parseData.awk}
\section{Band Mean}
\label{app:bandMean}
\lstinputlisting[caption=Band Mean Implementation, label = code:bandMean, language=R]{../PacketMetrics/bandMean.r}
\section{TDEVAllMethods}
\label{app:TDEVAll}
\lstinputlisting[caption=TDEV All Methods implementation, language = R]{../PacketMetrics/TDEVAllMethods.r}
\section{MATIEAllMethods}
\label{app:MATIEAll}
\lstinputlisting[caption=MATIE All Methods implementation, language = R]{../PacketMetrics/MATIEAllMethods.r}
\section{TDEV All Methods in C}
\label{app:TDEVAllC}
\lstinputlisting[caption = TDEV All Methods Implementation in C, language = C]{../PacketMetrics/TDEVAllMethods.c}
\section{MATIE MAFE All Methods in C}
\label{app:MATIEAllC}
\lstinputlisting[caption = MATIE/MAFE All Methods Implementation in C, language = C]{../PacketMetrics/MATIEAllMethods.c}
\section{Main Packet Metric Script}
\label{app:mainScript}
\lstinputlisting[caption=Main Packet Metric Script, language = R]{../PacketMetrics/PacketMetric.r}
\section{Plotting Function - Line}
\label{app:plot}
\begin{lstlisting}[language=R, caption=Plotting Function for Line Graphs]
plotArray <- function(values,whichPlot) {
	#Global Vars: args$nTest, N, 
	rangeOfValues <- range(0,values) #Determines a max range for the plot
	if (whichPlot == 0) metric = "TDEV" #TDEV
	else metric = "MATIE-MAFE"
	outputFileName = paste("../PTPData/Plots/Test: ", args$nTest, " - ", metric, " - ", N, " size.eps",sep = "")
	postscript(outputFileName)
	plottingColours = rainbow(ncol(values))
	plot(values[,1], type='o',xaxt='n', yaxt='n',pch='+',col=plottingColours[1],log="xy",xlab="", ylab="")
	for (i in 2:ncol(values)) { 
		#if (values[1,i] == 0) {
		#	loginfo("Column Ignored")
		#	continue
		#}
		lines(values[,i], type='o',pch='+',col=plottingColours[i])
	}
	legend(1,max(values[,2:ncol(values)]),colnames(values) , col=plottingColours, cex = 0.8,lty=1, pch='+', title="Metrics Legend",box.lwd = 0,box.col = "white",bg = "white") 
	if (metric == "TDEV") title(main=paste("Packet Metrics - TDEV - Sample Size", sampleSize),ylab="", xlab="Index/Time")
	else title(main=paste("Packet Metrics - MATIE-MAFE - Sample Size", sampleSize),ylab="", xlab="Index/Time")
	mtext(side = 2, text="    Index/Time", line = 3)
	axis(side = 1)
	axis(side = 2, las = 1)
	dev.off()
	loginfo(paste(metric, "Plot Created"))
}
\end{lstlisting}
\section{Plotting Functions - Histograms}
\label{app:hist}
\begin{lstlisting}[language=R]

plotHistogram <- function(data) { 
	
	outputFileName = paste("../PTPData/Plots/HistogramsOfDelays/Histogram of Delays - Test:", args\$nTest, " Sample - N", N, " size.eps",sep = "")
	postscript(outputFileName)
	hist(data, xlab = "Bins of Delay", ylab="Frequency", main = )

}
\end{lstlisting}
\section{Plotting Functions - Delay Plot}
\label{app:delay}
\begin{lstlisting}

plotDelay <- function(delay) {
	
	outputFileName = paste("../PTPData/Plots/PlotOfDelays/Plot of Delays - Test:", args\$nTest, " Sample -", N, " size.eps",sep = "")
	postscript(outputFileName)
	plot(delay * 1000, pch = 16, cex = .9, xlab = "Sample Number", ylab = "Delays (ms)")
}
\end{lstlisting}
\section{Plotting Functions - Colour Histogram}
\label{app:chist}
\begin{lstlisting}

plotCHistogram <- function (delay) { 
	# Work in Progress. Comment out all lines until it is completed
	#outputFileName = paste("../PTPData/Plots/PlotOfDelays/Colour Histogram of Delays - Test:", args\$nTest, " Sample -", N, " size.eps",sep = "")
	#postscript(outputFileName)
	step <- 32 * 60
	j <- 0
	#delay <- rnorm(n=5000,m=24.2,sd=2.2)
	# -- Flatten the histogram into their corresponding colours. 
	nStep <- floor(length(delay) / step ) # 100 steps for the time being. 
	colouredDelayArray = matrix(0,nStep,100) #temp matrix. need to define size
	bins <- seq(0.00000, 0.00010, by = 0.00005)
	
	for (i in seq(1, length(delay),by=step))  {
		if (is.na(delay[(i+step - 1)])) break
		histogram <- hist(delay[i:step + i - 1],breaks=30)\$counts
		colouredDelayArray[j,1:length(histogram)] <- histogram
		j = j + 1
	}
	png("simpleIm.png")
	
	image(log(t(colouredDelayArray[,1:30])), col=heat.colors(30,alpha=1))

}

\end{lstlisting}

\end{appendices}
\end{document}

